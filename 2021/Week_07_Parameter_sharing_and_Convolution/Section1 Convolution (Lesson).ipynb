{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson: Convolution Neural Network \n",
    "## 1.1 What area CNN is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN is adopted major in image process area<br>\n",
    "・Object Recognition<br>\n",
    "・Object Detection<br>\n",
    "・Image Generation etc...<br>\n",
    "CNN is the kind of theory in dealing with images, this neural network specialized in __extracting spacial features from input__ by convoluting the input with kernel filter. This model contributes better results in the image processing task than previous machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 About parameters of CNN\n",
    "<img src=imgs/fig1.png width=400 height=300>\n",
    "CNN consisted of mainly 3 parameters (覚えているかな？)<br>\n",
    "・Stride　<br>\n",
    "・Kernel Size　<br>\n",
    "・Padding　<br>\n",
    "CNN convoluted input striding kernel. Below animation is convolution process (kernel size=3, stride=1, padding=1)\n",
    "<img src=imgs/fig2.gif width=400 height=300>\n",
    "More stride size and kernel size make the feature map smaller (Below animation is process when kernel size=4, stride=2, padding=1)\n",
    "<img src=imgs/fig3.gif width=400 height=300>\n",
    "To extract strong (or moderate) features from feature map. \"Pooling layers\" are employed: Max pooling and Average pooling. The paremeters stride and kernel size are mainly used in this proceed.\n",
    "<img src=imgs/fig1-2.png width=400 height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 CNN vs Fully-Connected Network\n",
    "### ・Compare with weight paramters\n",
    "First, Fully-Connected Network is the network whose units conect to the other units at next layer like below figure with inputting gray img. Considering of the number of parameters, this nerwork needs \n",
    "$$\n",
    "N_{units}^i*N_{units}^{i+1}\\\\\n",
    "$$\n",
    "Then, when it comes to input RGB images, the parameters become larger and larger.\n",
    "<img src=imgs/fig4.png width=600 height=800>\n",
    "In the other hand, CNN is the network which utilizes the kaenel filter and obtain _N_ channels of feature map. As the result, the needed parameters of weight are mainly kernal size and output channel size.\n",
    "<img src=imgs/fig5.png width=600 height=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.4 Techniques of CNN\n",
    "### ・Local Reperesentive Field\n",
    "Let's see the below figure with a cat and a mouse. It is clear that cat's face and its ear have strong relationship in the object as a cat, on the other hand, cat's face and mouse face have far relationship.\n",
    "<img src=imgs/fig6.png width=600 height=800>\n",
    "When seeing the objects through image, there is the relationship in image processing that __near pixels have the strong relationship and far pixels have the weak one.__ Kernal filter in CNN works as local representative field that convolutes together with only near pixles.\n",
    "<img src=imgs/fig7.png width=600 height=800>\n",
    "### ・Parameter Sharing\n",
    "Next, let's see the blow figure with some dogs. You can recognize each objects as dog even if the color of far, shape and place is difference. Automatic recognition (or detection) model requires recognize the object without asking configuration.\n",
    "<img src=imgs/fig8.png width=600 height=800>\n",
    "Why we can recognize each of objects as dog is the object has significant features such as shape of mouth. Well, if the object has significant features, the other nealy object has the potential of consisting same features. The idea of Paramter Sharing is sharing the filter in per CNN layer.\n",
    "<img src=imgs/fig9.gif width=600 height=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.5 Transposed Convolution Neural Network\n",
    "CNN convolute input and extract the significant features. In the other hand, there is the CNN which reconstructs the input from feature maps. It is \"Transposed Convolution Neural Network\". Used parameters are same as CNN's, different points are the insert form of padding area and the output size becomes larger than input's. (Below figure and animation are the overview of the process of transposed CNN with stride=1, kernel size=3 and padding=1)\n",
    "<img src=imgs/fig10.png width=600 height=800>\n",
    "<img src=imgs/fig11.gif width=600 height=800>\n",
    "Transposed CNN is often used in image generative architecture like below lists.\n",
    "・Autoencoder\n",
    "・VAE\n",
    "・GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At \"Practice part Convolution\", let's see the number of parameter through constructing CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeworks (Writing)\n",
    "## 1.1 Write down what do you want to utilize CNN in detail.\n",
    "## 1.2 Write the difference between Fully-Connected Network and CNN is not only the needed number of paramters. Seach and explain the another difference.\n",
    " Hint: Let's focus on __the representation of input in each network.__\n",
    " ## 1.3 Below list describes the explations about CNN. Choose and point out the wrong sentenses. \n",
    " Hint: Wrong explation is not always one.\n",
    " ### 1. CNN contributes the improvement recognition task because of feedback to hidden layers.\n",
    " ### 2. As the representative field becomes larger and larger, CNN be able to obtain each of relationships among objects in the image.\n",
    " ### 3. Max pooling layer should be avoided using because it eliminates the weak pixel and tends to mistake result in recognition task.\n",
    " ### 4. Parameter sharing means loading the parameter of weights in trained CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
