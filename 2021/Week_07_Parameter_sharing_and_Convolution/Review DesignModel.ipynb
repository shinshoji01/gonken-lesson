{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson2: PytorchでModelを定義する\n",
    "- Lesson1では、pytorchでのDatasetの定義の仕方を紹介\n",
    "- 本演習では、Datasetのデータを扱う*深層学習モデルの作り方*を紹介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 本章で扱うモジュール\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Design1. Sequentialを使った定義\n",
    "    - 入力と出力が1対1のネットワークが作れる\n",
    "    - Sequentialの中に、処理をまとめて書くことはできるが**分岐条件などを取り入れた複雑なネットワークは作れない**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  =\n",
      "tensor([[ 0.7436,  0.2714,  1.0562],\n",
      "        [-0.9216, -1.2756,  0.4119],\n",
      "        [-0.2496,  0.3968, -1.5520],\n",
      "        [-1.6440, -0.9840,  2.5630],\n",
      "        [-0.1506,  0.8875,  1.8932]])\n",
      "output =\n",
      "tensor([[ 0.5036,  0.3235, -0.5669, -0.3003, -0.4349,  0.5386,  1.1480,  0.2871,\n",
      "         -1.0151, -0.2714],\n",
      "        [ 0.2948,  0.7309, -0.4578, -0.2791, -0.6015,  0.4593,  0.7650,  0.1899,\n",
      "         -0.9457, -0.2177],\n",
      "        [-0.2590,  0.4015, -0.8235,  0.2337, -0.1212, -0.0505,  0.3788, -0.0058,\n",
      "         -0.1648,  0.0127],\n",
      "        [ 0.7093,  1.1341, -0.1508, -0.7681, -0.9388,  0.9422,  1.1576,  0.3258,\n",
      "         -1.6541, -0.4454],\n",
      "        [ 0.5481,  0.6739, -0.4245, -0.4982, -0.5668,  0.7131,  1.1993,  0.2851,\n",
      "         -1.2697, -0.3534]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Step 1 モデルの定義\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.Linear(5, 10)\n",
    ")\n",
    "# Step 2 インプットデータの用意\n",
    "input = torch.randn(5,3)\n",
    "print('input  =\\n{}'.format(input))\n",
    "# Step 3 \n",
    "output = model(input)\n",
    "print('output =\\n{}'.format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input  =\n",
      "torch.Size([5, 3, 64, 64])\n",
      "output =\n",
      "torch.Size([5, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# 今度は畳み込み中心で\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1), # nn.Conv2dで画像の畳み込み\n",
    "    nn.ReLU(inplace=True),                                # nn.ReLUで活性化処理\n",
    "    nn.MaxPool2d(4,2,1),\n",
    "    nn.Conv2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
    "    nn.BatchNorm2d(64)\n",
    ")\n",
    "print(model)\n",
    "input = torch.randn(5, 3, 64, 64)\n",
    "print('input  =\\n{}'.format(input.size()))\n",
    "output = model(input)\n",
    "print('output =\\n{}'.format(output.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Design2. nn.Moduleを継承した定義\n",
    "    - ネットワークをクラスとして作成する\n",
    "    - __init__メソッド(初期化メソッド)にネットワークの定義を、forwardメソッドに順伝播の計算を書く\n",
    "    - 複雑なネットワークを定義できる、githubのpytorch関連でもこの形式で書かれるのがよく見かける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNetwork(\n",
      "  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (act0): ReLU(inplace=True)\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "output =\n",
      "torch.Size([5, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# クラス変数に関数を定義する書き方\n",
    "class myNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNetwork, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(3, 64, 3, 1, 1)\n",
    "        self.act0 = nn.ReLU(True)\n",
    "        self.conv1 = nn.Conv2d(64, 64, 4, 2, 1)\n",
    "        self.norm1 = nn.BatchNorm2d(64)\n",
    "    def forward(self, input):\n",
    "        x = self.conv0(input)\n",
    "        x = self.act0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        return x\n",
    "    \n",
    "model = myNetwork()\n",
    "print(model)\n",
    "input = torch.randn(5, 3, 64, 64)\n",
    "output = model(input)\n",
    "print('output =\\n{}'.format(output.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNetwork(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "output =\n",
      "torch.Size([5, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# クラス変数にSequentialで処理をまとめて定義する書き方 <-こちらの書き方はよく見かける\n",
    "class myNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNetwork, self).__init__()\n",
    "        self.conv = nn.Sequential(*[\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        ])\n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        return x\n",
    "\n",
    "model = myNetwork()\n",
    "print(model)\n",
    "input = torch.randn(5, 3, 64, 64)\n",
    "output = model(input)\n",
    "print('output =\\n{}'.format(output.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Design3. nn.ModuleListで楽に順伝播計算\n",
    "    - nn.Sequentialでは畳み込みや活性化関数等の処理をまとめて1つのクラス変数として定義することができたが、forwardメソッドで逐次対応するクラス変数を書く必要がある\n",
    "    - まとまった処理らをList化して、for文で処理を呼び出そう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNetwork(\n",
      "  (convs): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "output =\n",
      "torch.Size([5, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "class myNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNetwork, self).__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(*[\n",
    "                nn.Conv2d(3, 64, 4, 2, 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(True)\n",
    "            ]),\n",
    "            nn.Sequential(*[\n",
    "                nn.Conv2d(64, 64, 4, 2, 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(True)\n",
    "            ])\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for idx, m in enumerate(self.convs):\n",
    "            x = m(x)\n",
    "        return x\n",
    "\n",
    "model = myNetwork()\n",
    "print(model)\n",
    "input = torch.randn(5, 3, 64, 64)\n",
    "output = model(input)\n",
    "print('output =\\n{}'.format(output.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Design4. nn.ModuleDictで順伝播計算\n",
    "    - Pythonの辞書型といえば、{'apple':0, 'orange':1}のようにkey値とvalue値を紐づけて定義\n",
    "    - List型とは違って配列のindex番号を把握してなくても、自分で決めたkey値で呼び出せるので楽ですね\n",
    "    - 処理名を名前付きで定義できる辞書型と同じ機能があるので、知っておこう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNetwork(\n",
      "  (convs): ModuleDict(\n",
      "    (conv0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "output =\n",
      "torch.Size([5, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "class myNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNetwork, self).__init__()\n",
    "        self.convs = nn.ModuleDict({\n",
    "            'conv0': nn.Sequential(*[\n",
    "                nn.Conv2d(3, 64, 4, 2, 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(True)\n",
    "            ]),\n",
    "            'conv1': nn.Sequential(*[\n",
    "                nn.Conv2d(64, 64, 4, 2, 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(True)\n",
    "            ])\n",
    "        })\n",
    "    def forward(self, x):\n",
    "        x = self.convs['conv0'](x)\n",
    "        x = self.convs['conv1'](x)\n",
    "        return x\n",
    "\n",
    "model = myNetwork()\n",
    "print(model)\n",
    "input = torch.randn(5, 3, 64, 64)\n",
    "output = model(input)\n",
    "print('output =\\n{}'.format(output.size()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
