{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readings:\n",
    "\n",
    "- [Optuna tutorial](https://optuna.readthedocs.io/en/stable/tutorial/001_first.html#first)\n",
    "- [Multiobjective optimization](http://darden.hatenablog.com/entry/2017/05/26/234845)\n",
    "- [GIL](https://qiita.com/hikaru_/items/019b156861fc39cba838)\n",
    "- [Countermeasures against GIL](https://minus9d.hatenablog.com/entry/2017/10/26/231241)\n",
    "- [pygmo](https://esa.github.io/pygmo2/index.html)\n",
    "- [pygmo(pygmo.fast_non_dominated_sorting())](https://esa.github.io/pygmo2/mo_utils.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Overview\n",
    "1. Answers of the homework\n",
    "1. Introduction to implementation of Optuna\n",
    "1. What's Multi-Objective Optimization?\n",
    "1. Pareto optimal solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Answers of the homework\n",
    "\n",
    "## Exercise \n",
    "(I thought you would be very busy with your graduation thesis, so I reduced the number of questions this time.)\n",
    "\n",
    "(1) Write the most appropriate optimizing method for hyperparameters in the following cases.\n",
    "\n",
    "1-1 When the hyperparameter takes discrete values as values and the number of combinations is not so large.\n",
    "\n",
    "-> Grid search\n",
    "\n",
    "1-2 When the hyperparameter takes a continuous value as a value and the number of combinations is very large. (There is more than one answer, so please write the one you like.)\n",
    "\n",
    "-> Randomized search, Bayesian optimization, GA (rcGA() of vcopt)\n",
    "\n",
    "(2) Describe your research briefly, and write whether you think one of the methods listed in this lecture is appropriate for optimizing hyperparameters in your research, including reasons.\n",
    "\n",
    "-> . . .\n",
    "\n",
    "## Additional exercise\n",
    "\n",
    "(3) Add learning iteration as a hyperparameter to the code of GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyEstimator(BaseEstimator):\n",
    "    def __init__(self, param01, param02, param03, param04, param05, param06, param07, param08):#\n",
    "        self.param01 = int(param01)\n",
    "        self.param02 = int(param02)\n",
    "        self.param03 = int(param03)\n",
    "        self.param04 = int(param04)\n",
    "        self.param05 = int(param05)\n",
    "        self.param06 = int(param06)\n",
    "        self.param07 = int(param07)\n",
    "        self.param06 = int(param08)#\n",
    "        \n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04,self.param05, self.param06, self.param07, self.param08)#\n",
    "        self.df = pd.read_csv(CSV_PATH, header=0)\n",
    "    \n",
    "    def make_string(self, param01, param02, param03, param04, param05, param06, param07, param08):#\n",
    "        #param1\n",
    "        noiseReduction = [\"Gaussian:7 \",\"Gaussian:7 Gaussian:7 \",\"Gaussian:7 Gaussian:7 Gaussian:7 \"]\n",
    "        #param2\n",
    "        filtersize_1 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "        #param3\n",
    "        filtersize_2 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "        #param4\n",
    "        padding = [\"1 \",\"3 \",\"5 \"]\n",
    "        #param5\n",
    "        activation_function_1 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "        #param6\n",
    "        activation_function_2 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "        #param7\n",
    "        optimization = [\"Adam\",\"RMSProp\",\"AdaGrad\"]\n",
    "        #param8\n",
    "        learning_iteration = [\"100\",\"200\",\"300\"]#\n",
    "        \n",
    "        self.param01_str = noiseReduction[param01 - 1]\n",
    "        self.param02_str = filtersize_1[param02 - 1]\n",
    "        self.param03_str = filtersize_2[param03 - 1]\n",
    "        self.param04_str = padding[param04 - 1]\n",
    "        self.param05_str = activation_function_1[param05 - 1]\n",
    "        self.param06_str = activation_function_2[param06 - 1]\n",
    "        self.param07_str = optimization[param07 - 1]\n",
    "        self.param08_str = learning_iteration[param08 - 1]#\n",
    "        \n",
    "        self.search_str = (self.param01_str + self.param02_str + self.param03_str + self.param04_str + self.param05_str + self.param06_str + self.param07_str + self.param08_str)#\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self \n",
    "    \n",
    "    def predict(self, x):\n",
    "        return [1.0]*len(x)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08)#\n",
    "        judge_value = float(MyEstimator(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08).search_data())#\n",
    "        return judge_value\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'param01': self.param01, 'param02': self.param02, 'param03': self.param03, 'param04': self.param04, 'param05': self.param05, 'param06': self.param06, 'param07': self.param07, 'param08': self.param08}#\n",
    "                \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def search_data(self):\n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08)#\n",
    "        \n",
    "        return float(self.df[self.df['param'] == self.search_str]['Evaluation Value'])\n",
    "\n",
    "param01 = 1\n",
    "param02 = 1\n",
    "param03 = 1\n",
    "param04 = 1\n",
    "param05 = 1\n",
    "param06 = 1\n",
    "param07 = 1\n",
    "param08 = 1#\n",
    "CSV_PATH  = \"data_13/data.csv\"\n",
    "\n",
    "searchEstimator = MyEstimator(param01, param02, param03, param04, param05, param06, param07, param08)#\n",
    "value = searchEstimator.search_data()\n",
    "\n",
    "param_dist = {\"param01\":[1,2,3],\n",
    "              \"param02\":[1,2,3,4],\n",
    "              \"param03\":[1,2,3,4],\n",
    "              \"param04\":[1,2,3],\n",
    "              \"param05\":[1,2,3,4],\n",
    "              \"param06\":[1,2,3,4],\n",
    "              \"param07\":[1,2,3],\n",
    "              \"param08\":[1,2,3]#\n",
    "              }\n",
    "\n",
    "model_grid = GridSearchCV(  estimator = searchEstimator, \n",
    "                                    param_grid = param_dist,\n",
    "                                    cv=2,              #CV default=None クロスバリデーションの分割方法を決定\n",
    "                                    #scoring=\"accuracy\",#metrics モデル評価ルールを記述する\n",
    "                                    return_train_score=False,\n",
    "                                    n_jobs=-1           #num of core -1は全てのコアを利用\n",
    "                                    #verbose=0,          \n",
    "                                    #random_state=2, #乱数のSEEDを指定\n",
    "                                    #return_train_score = True #スコアを返すか返さないか\n",
    "                                    #scoring = 'roc_auc'\n",
    "                                    #scoring = scoring\n",
    "                                    ,refit=True\n",
    "                                    )\n",
    "\n",
    "x = searchEstimator.df[\"param\"]\n",
    "y = searchEstimator.df[\"Evaluation Value\"].values\n",
    "\n",
    "model_grid.fit(x,y)\n",
    "result_df = pd.DataFrame(model_grid.cv_results_)\n",
    "print(result_df)\n",
    "print(\"##################################\")\n",
    "print(model_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Add learning iteration as a hyperparameter to the code of RandmizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyEstimator(BaseEstimator):\n",
    "    def __init__(self, param01, param02, param03, param04, param05, param06, param07, param08):#\n",
    "        self.param01 = int(param01)\n",
    "        self.param02 = int(param02)\n",
    "        self.param03 = int(param03)\n",
    "        self.param04 = int(param04)\n",
    "        self.param05 = int(param05)\n",
    "        self.param06 = int(param06)\n",
    "        self.param07 = int(param07)\n",
    "        self.param06 = int(param08)#\n",
    "        \n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04,self.param05, self.param06, self.param07, self.param08)#\n",
    "        self.df = pd.read_csv(CSV_PATH, header=0)\n",
    "    \n",
    "    def make_string(self, param01, param02, param03, param04, param05, param06, param07, param08):#\n",
    "        #param1\n",
    "        noiseReduction = [\"Gaussian:7 \",\"Gaussian:7 Gaussian:7 \",\"Gaussian:7 Gaussian:7 Gaussian:7 \"]\n",
    "        #param2\n",
    "        filtersize_1 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "        #param3\n",
    "        filtersize_2 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "        #param4\n",
    "        padding = [\"1 \",\"3 \",\"5 \"]\n",
    "        #param5\n",
    "        activation_function_1 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "        #param6\n",
    "        activation_function_2 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "        #param7\n",
    "        optimization = [\"Adam\",\"RMSProp\",\"AdaGrad\"]\n",
    "        #param8\n",
    "        learning_iteration = [\"100\",\"200\",\"300\"]#\n",
    "        \n",
    "        self.param01_str = noiseReduction[param01 - 1]\n",
    "        self.param02_str = filtersize_1[param02 - 1]\n",
    "        self.param03_str = filtersize_2[param03 - 1]\n",
    "        self.param04_str = padding[param04 - 1]\n",
    "        self.param05_str = activation_function_1[param05 - 1]\n",
    "        self.param06_str = activation_function_2[param06 - 1]\n",
    "        self.param07_str = optimization[param07 - 1]\n",
    "        self.param08_str = learning_iteration[param08 - 1]#\n",
    "        \n",
    "        self.search_str = (self.param01_str + self.param02_str + self.param03_str + self.param04_str + self.param05_str + self.param06_str + self.param07_str + self.param08_str)#\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self \n",
    "    \n",
    "    def predict(self, x):\n",
    "        return [1.0]*len(x)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08)#\n",
    "        judge_value = float(MyEstimator(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08).search_data())#\n",
    "        return judge_value\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'param01': self.param01, 'param02': self.param02, 'param03': self.param03, 'param04': self.param04, 'param05': self.param05, 'param06': self.param06, 'param07': self.param07, 'param08': self.param08}#\n",
    "                \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def search_data(self):\n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08)#\n",
    "        \n",
    "        return float(self.df[self.df['param'] == self.search_str]['Evaluation Value'])\n",
    "\n",
    "param01 = 1\n",
    "param02 = 1\n",
    "param03 = 1\n",
    "param04 = 1\n",
    "param05 = 1\n",
    "param06 = 1\n",
    "param07 = 1\n",
    "param08 = 1#\n",
    "CSV_PATH  = \"data_13/data.csv\"\n",
    "\n",
    "searchEstimator = MyEstimator(param01, param02, param03, param04, param05, param06, param07, param08)#\n",
    "value = searchEstimator.search_data()\n",
    "\n",
    "param_dist = {\"param01\":[1,2,3],\n",
    "              \"param02\":[1,2,3,4],\n",
    "              \"param03\":[1,2,3,4],\n",
    "              \"param04\":[1,2,3],\n",
    "              \"param05\":[1,2,3,4],\n",
    "              \"param06\":[1,2,3,4],\n",
    "              \"param07\":[1,2,3],\n",
    "              \"param08\":[1,2,3]#\n",
    "              }\n",
    "\n",
    "model_random = RandomizedSearchCV(  estimator = searchEstimator, \n",
    "                                    param_distributions = param_dist,\n",
    "                                    #cv=3,              #CV default=None クロスバリデーションの分割方法を決定\n",
    "                                    n_iter = 20,        #何パターンまでrando searchで調べるか指定 default:10\n",
    "                                    #scoring=\"accuracy\",#metrics モデル評価ルールを記述する。\n",
    "                                    n_jobs=-1           #num of core -1は全てのコアを利用\n",
    "                                    #verbose=0,          \n",
    "                                    #random_state=2, #乱数seed\n",
    "                                    #return_train_score = True #スコアを返すか返さないか\n",
    "                                    #scoring = 'roc_auc'\n",
    "                                    #scoring = scoring\n",
    "                                    ,refit = False\n",
    "                                    )\n",
    "\n",
    "\n",
    "x = searchEstimator.df[\"param\"]\n",
    "y = searchEstimator.df[\"Evaluation Value\"].values\n",
    "model_random.fit(x,y)\n",
    "result_df = pd.DataFrame(model_random.cv_results_)\n",
    "\n",
    "print(result_df)\n",
    "print(\"##################################\")\n",
    "print(model_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Add learning iteration as a hyperparameter to the code of Baysian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "class MyEstimator(BaseEstimator):\n",
    "    def __init__(self, param01, param02, param03, param04, param05, param06, param07, param08):#\n",
    "        self.param01 = int(param01)\n",
    "        self.param02 = int(param02)\n",
    "        self.param03 = int(param03)\n",
    "        self.param04 = int(param04)\n",
    "        self.param05 = int(param05)\n",
    "        self.param06 = int(param06)\n",
    "        self.param07 = int(param07)\n",
    "        self.param06 = int(param08)#\n",
    "        \n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04,self.param05, self.param06, self.param07, self.param08)#\n",
    "        self.df = pd.read_csv(CSV_PATH, header=0)\n",
    "    \n",
    "    def make_string(self, param01, param02, param03, param04, param05, param06, param07, param08):#\n",
    "        #param1\n",
    "        noiseReduction = [\"Gaussian:7 \",\"Gaussian:7 Gaussian:7 \",\"Gaussian:7 Gaussian:7 Gaussian:7 \"]\n",
    "        #param2\n",
    "        filtersize_1 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "        #param3\n",
    "        filtersize_2 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "        #param4\n",
    "        padding = [\"1 \",\"3 \",\"5 \"]\n",
    "        #param5\n",
    "        activation_function_1 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "        #param6\n",
    "        activation_function_2 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "        #param7\n",
    "        optimization = [\"Adam\",\"RMSProp\",\"AdaGrad\"]\n",
    "        #param8\n",
    "        learning_iteration = [\"100\",\"200\",\"300\"]#\n",
    "        \n",
    "        self.param01_str = noiseReduction[param01 - 1]\n",
    "        self.param02_str = filtersize_1[param02 - 1]\n",
    "        self.param03_str = filtersize_2[param03 - 1]\n",
    "        self.param04_str = padding[param04 - 1]\n",
    "        self.param05_str = activation_function_1[param05 - 1]\n",
    "        self.param06_str = activation_function_2[param06 - 1]\n",
    "        self.param07_str = optimization[param07 - 1]\n",
    "        self.param08_str = learning_iteration[param08 - 1]#\n",
    "        \n",
    "        self.search_str = (self.param01_str + self.param02_str + self.param03_str + self.param04_str + self.param05_str + self.param06_str + self.param07_str + self.param08_str)#\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self \n",
    "    \n",
    "    def predict(self, x):\n",
    "        return [1.0]*len(x)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08)#\n",
    "        judge_value = float(MyEstimator(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08).search_data())#\n",
    "        return judge_value\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'param01': self.param01, 'param02': self.param02, 'param03': self.param03, 'param04': self.param04, 'param05': self.param05, 'param06': self.param06, 'param07': self.param07, 'param08': self.param08}#\n",
    "                \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def search_data(self):\n",
    "        self.make_string(self.param01, self.param02, self.param03, self.param04, self.param05, self.param06, self.param07, self.param08)#\n",
    "        \n",
    "        return float(self.df[self.df['param'] == self.search_str]['Evaluation Value'])\n",
    "\n",
    "param01 = 1\n",
    "param02 = 1\n",
    "param03 = 1\n",
    "param04 = 1\n",
    "param05 = 1\n",
    "param06 = 1\n",
    "param07 = 1\n",
    "param08 = 1#\n",
    "CSV_PATH  = \"data_13/data.csv\"\n",
    "\n",
    "bayesEstimator = MyEstimator(param01, param02, param03, param04, param05, param06, param07, param08)#\n",
    "value = searchEstimator.search_data()\n",
    "\n",
    "param_dist = {\"param01\":[1,2,3],\n",
    "              \"param02\":[1,2,3,4],\n",
    "              \"param03\":[1,2,3,4],\n",
    "              \"param04\":[1,2,3],\n",
    "              \"param05\":[1,2,3,4],\n",
    "              \"param06\":[1,2,3,4],\n",
    "              \"param07\":[1,2,3],\n",
    "              \"param08\":[1,2,3]#\n",
    "              }\n",
    "\n",
    "\n",
    "model_bayes = BayesSearchCV(estimator = bayesEstimator,\n",
    "                                #param_distributions = param_dist,\n",
    "                                search_spaces = param_dist,\n",
    "                                cv = 2,              #CV default=None クロスバリデーションの分割方法を決定\n",
    "                                n_iter = 10,         #おおよそ22回まででサンプリング点が収束した為、この値とした。\n",
    "                                #何パターンまで調べるかの指定が必要 default:50(BayesSearchCVの場合) \n",
    "                                #interation numサンプリングされるパラメータ設定の数。 \n",
    "                                #n_iterは実行時間とソリューションの品質をトレードオフにします。\n",
    "                                #scoring=\"accuracy\", #metrics モデル評価ルールを記述する。\n",
    "                                n_jobs= -1,           #num of core -1は全てのコアを利用\n",
    "                                #verbose=0,          \n",
    "                                #random_state=2, #乱数seed\n",
    "                                #return_train_score = True #スコアを返すか返さないか\n",
    "                                #scoring = 'roc_auc'\n",
    "                                #scoring = scoring\n",
    "                                #search_spaces=param_grid,\n",
    "                                #refit=True\n",
    "                                #fit_params = pass_params\n",
    "                                )\n",
    "\n",
    "x = bayesEstimator.df[\"param\"]\n",
    "y = bayesEstimator.df[\"Evaluation Value\"].values\n",
    "\n",
    "\n",
    "model_bayes.fit(x,y)\n",
    "result_df = pd.DataFrame(model_bayes.cv_results_)\n",
    "\n",
    "print(result_df)\n",
    "print(\"##################################\")\n",
    "print(model_bayes.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Add learning iteration as a hyperparameter to the code of GA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from vcopt import vcopt\n",
    "\n",
    "#評価関数\n",
    "def score_func(params):\n",
    "    search_str = make_string_for_GA(params[0],params[1],params[2],\n",
    "                                    params[3],params[4],params[5],params[6],params[7])#\n",
    "    \n",
    "    judge_value = float(df[df['param'] == search_str]['Evaluation Value'])\n",
    "\n",
    "    return judge_value\n",
    "\n",
    "def show_pool_func(pool, **info):\n",
    "    #GA中の諸情報はinfoという辞書に格納されて渡される\n",
    "    #これらを受け取って使用することができる\n",
    "    gen = info['gen'] #現在の世代\n",
    "    best_index = info['best_index'] #エリート個体のインデックス\n",
    "    best_score = info['best_score'] #エリート個体の評価値\n",
    "    mean_score = info['mean_score'] #個体群の平均評価値\n",
    "    mean_gap = info['mean_gap'] #目標値と評価値の差の絶対値平均\n",
    "    time = info['time'] #経過時間（秒）\n",
    "\n",
    "    #可視化\n",
    "    print(gen, best_score, best_index, time)\n",
    "\n",
    "def make_string_for_GA(param01, param02, param03, param04, param05, param06, param07, param08):\n",
    "    #param1\n",
    "    noiseReduction = [\"Gaussian:7 \",\"Gaussian:7 Gaussian:7 \",\"Gaussian:7 Gaussian:7 Gaussian:7 \"]\n",
    "    #param2\n",
    "    filtersize_1 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "    #param3\n",
    "    filtersize_2 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "    #param4\n",
    "    padding = [\"1 \",\"3 \",\"5 \"]\n",
    "    #param5\n",
    "    activation_function_1 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "    #param6\n",
    "    activation_function_2 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "    #param7\n",
    "    optimization = [\"Adam\",\"RMSProp\",\"AdaGrad\"]\n",
    "    #param8\n",
    "    learning_iteration = [\"100\",\"200\",\"300\"]#\n",
    "\n",
    "    param01_str = noiseReduction[param01 - 1]\n",
    "    param02_str = filtersize_1[param02 - 1]\n",
    "    param03_str = filtersize_2[param03 - 1]\n",
    "    param04_str = padding[param04 - 1]\n",
    "    param05_str = activation_function_1[param05 - 1]\n",
    "    param06_str = activation_function_2[param06 - 1]\n",
    "    param07_str = optimization[param07 - 1]\n",
    "    param08_str = learning_iteration[param08 - 1]#\n",
    "    \n",
    "    return (param01_str + param02_str + param03_str + param04_str + param05_str + param06_str + param07_str + param08_str)#\n",
    "\n",
    "param01 = 1\n",
    "param02 = 1\n",
    "param03 = 1\n",
    "param04 = 1\n",
    "param05 = 1\n",
    "param06 = 1\n",
    "param07 = 1\n",
    "param08 = 1#\n",
    "CSV_PATH  = \"data_13/data.csv\"\n",
    "\n",
    "# データ生成と配列の確保\n",
    "df = pd.read_csv(CSV_PATH, header=0)\n",
    "dataX = df[\"param\"]\n",
    "dataY = df[\"Evaluation Value\"].values\n",
    "\n",
    "target_str = make_string_for_GA(param01, param02, param03, param04, param05, param06, param07, param08)#\n",
    "target_value = float(df[df['param'] == target_str]['Evaluation Value'])\n",
    "\n",
    "search_str = \"\"\n",
    "param_range = [[1,2,3], [1,2,3,4], [1,2,3,4], [1,2,3], [1,2,3,4], [1,2,3,4], [1,2,3], [1,2,3]]#\n",
    "\n",
    "para, score = vcopt().dcGA(param_range ,\n",
    "                               score_func,\n",
    "                               9999, #最大化\n",
    "                               show_pool_func = 'data/',\n",
    "                               seed = None, #乱数seedを指定\n",
    "                               pool_num = 100 #個体数を指定\n",
    "                               ,max_gen = 2000 #最大世代数を指定\n",
    "                               )\n",
    "\n",
    "print(para, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to implementation of Optuna\n",
    "\n",
    "Since we have a lot of time for this lecture, I explain how to implement Optuna, a library for Bayesian optimization.\n",
    "\n",
    "- [Optuna](https://optuna.readthedocs.io/en/stable/tutorial/001_first.html#first)\n",
    "\n",
    "pip install optuna\n",
    "\n",
    "↑ If you run this command, you can run following code.\n",
    "\n",
    "--\n",
    "\n",
    "# Optunaの実装紹介\n",
    "\n",
    "時間が大分余ってしまいそうだったので、ベイズ最適のライブラリである\n",
    "\n",
    "- [Optuna](https://optuna.readthedocs.io/en/stable/tutorial/001_first.html#first)\n",
    "\n",
    "の実装も簡単に紹介します。\n",
    "\n",
    "pip install optuna\n",
    "\n",
    "でoptunaをinstallすることで下記のコードが実行可能となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-07 17:04:50,680]\u001b[0m A new study created in memory with name: no-name-9b6884e1-ebc5-484b-bc55-d6c55423c276\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:51,523]\u001b[0m Trial 0 finished with value: 0.755199961 and parameters: {'param01': 2, 'param02': 2, 'param03': 2, 'param04': 2, 'param05': 2, 'param06': 2, 'param07': 2}. Best is trial 0 with value: 0.755199961.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:52,333]\u001b[0m Trial 1 finished with value: 0.784640296 and parameters: {'param01': 1, 'param02': 3, 'param03': 1, 'param04': 3, 'param05': 3, 'param06': 1, 'param07': 3}. Best is trial 1 with value: 0.784640296.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:53,137]\u001b[0m Trial 2 finished with value: 1.19603394 and parameters: {'param01': 2, 'param02': 4, 'param03': 4, 'param04': 3, 'param05': 4, 'param06': 2, 'param07': 2}. Best is trial 2 with value: 1.19603394.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:53,927]\u001b[0m Trial 3 finished with value: 0.619190374 and parameters: {'param01': 3, 'param02': 4, 'param03': 2, 'param04': 1, 'param05': 3, 'param06': 1, 'param07': 2}. Best is trial 2 with value: 1.19603394.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:54,736]\u001b[0m Trial 4 finished with value: 0.257906914 and parameters: {'param01': 3, 'param02': 1, 'param03': 4, 'param04': 3, 'param05': 2, 'param06': 4, 'param07': 2}. Best is trial 2 with value: 1.19603394.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:55,533]\u001b[0m Trial 5 finished with value: 0.862609159 and parameters: {'param01': 1, 'param02': 3, 'param03': 1, 'param04': 2, 'param05': 3, 'param06': 1, 'param07': 3}. Best is trial 2 with value: 1.19603394.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:56,454]\u001b[0m Trial 6 finished with value: 0.190476213 and parameters: {'param01': 1, 'param02': 4, 'param03': 1, 'param04': 1, 'param05': 1, 'param06': 2, 'param07': 3}. Best is trial 2 with value: 1.19603394.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:57,269]\u001b[0m Trial 7 finished with value: 1.6198535269999998 and parameters: {'param01': 3, 'param02': 1, 'param03': 3, 'param04': 2, 'param05': 4, 'param06': 3, 'param07': 3}. Best is trial 7 with value: 1.6198535269999998.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:58,059]\u001b[0m Trial 8 finished with value: 0.023283752999999997 and parameters: {'param01': 3, 'param02': 4, 'param03': 1, 'param04': 3, 'param05': 2, 'param06': 4, 'param07': 3}. Best is trial 7 with value: 1.6198535269999998.\u001b[0m\n",
      "\u001b[32m[I 2021-01-07 17:04:58,994]\u001b[0m Trial 9 finished with value: 0.631871219 and parameters: {'param01': 1, 'param02': 1, 'param03': 3, 'param04': 1, 'param05': 4, 'param06': 1, 'param07': 2}. Best is trial 7 with value: 1.6198535269999998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'param01': 3, 'param02': 1, 'param03': 3, 'param04': 2, 'param05': 4, 'param06': 3, 'param07': 3}\n",
      "##################\n",
      "1.6198535269999998\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "\n",
    "# scipyの評価関数\n",
    "def func(self, X, Y):\n",
    "    search_str = make_string()\n",
    " \n",
    "    judge_value = float(df[df['param'] == search_str]['Evaluation Value'])\n",
    "\n",
    "    return judge_value\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    global param01\n",
    "    global param02\n",
    "    global param03\n",
    "    global param04\n",
    "    global param05\n",
    "    global param06\n",
    "    global param07\n",
    "\n",
    "    param01 = trial.suggest_categorical('param01', [1,2,3])\n",
    "    param02 = trial.suggest_categorical('param02', [1,2,3,4])\n",
    "    param03 = trial.suggest_categorical('param03', [1,2,3,4])\n",
    "    param04 = trial.suggest_categorical('param04', [1,2,3])\n",
    "    param05 = trial.suggest_categorical('param05', [1,2,3,4])\n",
    "    param06 = trial.suggest_categorical('param06', [1,2,3,4])\n",
    "    param07 = trial.suggest_categorical('param07', [1,2,3])\n",
    "    \n",
    "    # 学習処理に該当する操作\n",
    "    np.random.seed(0)\n",
    "    arg = (dataX, dataY, )\n",
    "\n",
    "    for i in range(10):\n",
    "        param = np.random.randint(1, 12, 3)\n",
    "        param_list[i] = optimize.fmin(func, param, args=arg, disp=False, full_output=False)\n",
    " \n",
    "    search_str = make_string()\n",
    "\n",
    "    return float(df[df['param'] == search_str]['Evaluation Value'])\n",
    "\n",
    "def make_string():\n",
    "    global param01\n",
    "    global param02\n",
    "    global param03\n",
    "    global param04\n",
    "    global param05\n",
    "    global param06\n",
    "    global param07\n",
    "    \n",
    "    #param1\n",
    "    noiseReduction = [\"Gaussian:7 \",\"Gaussian:7 Gaussian:7 \",\"Gaussian:7 Gaussian:7 Gaussian:7 \"]\n",
    "    #param2\n",
    "    filtersize_1 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "    #param3\n",
    "    filtersize_2 = [\"3 \",\"5 \",\"7 \",\"9 \"]\n",
    "    #param4\n",
    "    padding = [\"1 \",\"3 \",\"5 \"]\n",
    "    #param5\n",
    "    activation_function_1 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "    #param6\n",
    "    activation_function_2 = [\"softmax \",\"relu \",\"sigmoid \",\"tanh \"]\n",
    "    #param7\n",
    "    optimization = [\"Adam\",\"RMSProp\",\"AdaGrad\"]\n",
    "\n",
    "    param01_str = noiseReduction[param01 - 1]\n",
    "    param02_str = filtersize_1[param02 - 1]\n",
    "    param03_str = filtersize_2[param03 - 1]\n",
    "    param04_str = padding[param04 - 1]\n",
    "    param05_str = activation_function_1[param05 - 1]\n",
    "    param06_str = activation_function_2[param06 - 1]\n",
    "    param07_str = optimization[param07 - 1]\n",
    "    \n",
    "    return (param01_str + param02_str + param03_str + param04_str + param05_str + param06_str + param07_str)\n",
    "\n",
    "param01 = 1\n",
    "param02 = 1\n",
    "param03 = 1\n",
    "param04 = 1\n",
    "param05 = 1\n",
    "param06 = 1\n",
    "param07 = 1\n",
    "\n",
    "CSV_PATH  = \"data_13/data.csv\"\n",
    "\n",
    "# データ生成と配列の確保\n",
    "df = pd.read_csv(CSV_PATH, header=0)\n",
    "dataX = df[\"param\"]\n",
    "dataY = df[\"Evaluation Value\"].values\n",
    "\n",
    "target_str = make_string()\n",
    "target_value = float(df[df['param'] == target_str]['Evaluation Value'])\n",
    "\n",
    "search_str = \"\"\n",
    "param_list = np.zeros((10, 3)) \n",
    "\n",
    "study = optuna.create_study(direction='maximize')#最大化を指定\n",
    "study.optimize(objective, n_trials=10)#何点まで探査するか\n",
    "result_df = study.trials_dataframe()#実行結果を格納\n",
    "trial = study.best_trial#最良結果を格納\n",
    "score = trial.value#最良結果のscoreを格納\n",
    "print(trial.params)#最良結果のパラメータを表示\n",
    "print(\"##################\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# What's Multi-Objective Optimization?\n",
    "\n",
    "An optimization problem with multiple objective functions is called a multi-objective optimization problem. One way to solve a multi-objective optimization is to set appropriate weights for each objective function and change the problem to an optimization problem with a single objective function. However, there are cases where we want to consider multiple objective functions as they are. In such cases, it is necessary to introduce a new way of thinking, starting from the definition of the optimal solution.\n",
    "\n",
    "A simple extension of the concept of optimization to multi-objective optimization is called a fully optimal solution. Intuitively, this has the property of being optimal for any objective function.Mathematically, the necessary and sufficient condition for x* to be a fully optimal solution in the following multi-objective optimization problem \n",
    "\n",
    "<img src=\"implements_14/pareto_opt_1.jpg\" width=\"200\">\n",
    "\n",
    "is as follows.\n",
    "\n",
    "<img src=\"implements_14/pareto_opt_2.jpg\" width=\"300\">\n",
    "\n",
    "Unlike the case of single-objective optimization problems, the perfect optimal solution does not always exist. In the fortunate case that there is a common part in the set of optimal solutions for each objective function, a perfect optimal solution exists, but usually the optimal x for one objective function is not optimal for other objective functions.\n",
    "\n",
    "--\n",
    "\n",
    "# 多目的最適化とは\n",
    "\n",
    "目的関数が複数存在する最適化問題を多目的最適化問題と呼ぶ。多目的最適化を解く一つの方法としては、各目的関数に適当な重みを設定し，単一の目的関数を有する最適化問題に変更するという方法が挙げられる。しかしながら、複数の目的関数をそのまま考慮したいという場合も存在し、その場合にはそもそも最適解の定義から，新たな考え方の導入が必要になる．\n",
    "\n",
    "通常の最適化の概念の多目的最適化への単純な拡張は、完全最適解と呼ばれる。これは、直感的には、どの目的関数に対しても最適という性質を持つ．数学的には，次の多目的最適化問題\n",
    "\n",
    "<img src=\"implements_14/pareto_opt_1.jpg\" width=\"200\">\n",
    "\n",
    "に於いて、x*　が完全最適解であるための必要十分条件は\n",
    "\n",
    "<img src=\"implements_14/pareto_opt_2.jpg\" width=\"300\">\n",
    "\n",
    "と記述される。\n",
    "\n",
    "単目的の最適化問題の場合と異なり、完全最適解は常に存在するとは限らない。各目的関数に対する個別の最適解集合に共通部分が存在する、という幸運なケースでは完全最適解が存在するが、通常はある目的関数に対して最適な x は他の目的関数に対しては最適ではない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Pareto optimal solution\n",
    "\n",
    "In order to deal with the aforementioned problems, the concept of Pareto optimality was invented. This is a condition of optimality in a multi-objective optimization problem that states \"there is no solution that is better than the current one in at least all objective functions\".\n",
    "\n",
    "For example, when looking for a house, one house has a high rent but is close to the station, and the other house has a low rent but is far from the station, but there is no house that is closer to the station and has a lower rent than either house. In such a case, it is up to the person to decide which house is better. This kind of optimal solution, in which the superiority or inferiority changes depending on the person, is called Pareto optimal solution.\n",
    "\n",
    "Mathematically, in a multi-objective optimization problem such as the one described above, x* is a Pareto optimal solution in the following situation.\n",
    "\n",
    "<img src=\"implements_14/pareto_opt_3.jpg\" width=\"350\">\n",
    "\n",
    "A relaxation of the definition to allow for equality of sign of inequality is called weakly Pareto optimal.\n",
    "\n",
    "<img src=\"implements_14/pareto_opt_4.jpg\" width=\"320\">\n",
    "\n",
    "The following is an example of code that extracts the Pareto optimal solution. (For every value that the object being compared (let's call this myself) has, compare all the values of the other object (let's call this  opponent), and when you have finished comparing all the values of the opponent, compare myself with the next opponent, and determine if you are the Pareto optimal solution by comparing myself with all the opponents that exist.)\n",
    "\n",
    "--\n",
    "\n",
    "# パレート最適解\n",
    "\n",
    "前述のような問題に対処するために、パレート最適という概念が考え出された。これは、多目的最適化問題において\"少なくとも全ての目的関数において現状より良い解は存在しない\"という状態を表す最適性の条件のことである。\n",
    "\n",
    "例えば、家を探す際に、こっちの家は家賃が高いが駅から近い、あっちの家は家賃が安いが駅から遠いが、どちらの家よりも駅から近く、かつこれ以上家賃が安いというような家はないというような場合を考える。そのような時に、どちらの家の方が良いかはその人次第である。このような、人によって優劣が変わるような最適解のことをパレート最適解と言う。\n",
    "\n",
    "数学的には，前述のような多目的最適化問題に於いて、x*　がパレート最適解であるとは、\n",
    "\n",
    "<img src=\"implements_14/pareto_opt_3.jpg\" width=\"350\">\n",
    "\n",
    "という状況のことである。\n",
    "\n",
    "不等号の等号を許すように定義を緩和したものは，弱パレート最適と呼ばれる．\n",
    "\n",
    "<img src=\"implements_14/pareto_opt_4.jpg\" width=\"320\">\n",
    "\n",
    "パレート最適解を抽出するコード例は以下の通り。（比較される対象（これを自分自身と呼ぶことにする）が持つ全ての値に対して、比較する対象（これを相手とする）の全ての値を比較し、相手の全ての値を比較し終わったら、次の相手と自分自身を比較し、存在する相手全てと比較を行うことによって自分自身がパレート最適解であるかどうかを判定する。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as multi\n",
    "from argparse import ArgumentParser\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "def translation_data(input_data, target_params):\n",
    "\ttranslated = input_data.copy()\n",
    "\tfor line_target in target_params.itertuples():\n",
    "\t\tif line_target[2] == 1:\n",
    "\t\t\tcolum_name = translated.columns[line_target[1]]\n",
    "\t\t\tmax_value = translated[colum_name].max()\t\n",
    "\t\t\tfor i in range(len(translated.index)):\n",
    "\t\t\t\ttranslated.iloc[i,line_target[1]] = float(max_value) + 1 - float(translated.iloc[i,line_target[1]])\n",
    "\t\t\t\ti += 1\n",
    "\treturn translated\n",
    "\n",
    "def main(line, target_para, translated_df, input_df):\n",
    "\tpareto_solution = []\n",
    "\tnot_pareto_flag = 0\n",
    "\n",
    "\t#相手変更ブロック\n",
    "\tfor index2 in range(len(translated_df.index)):\n",
    "\t\tnot_pareto_possibility = 0 #相手が自分にいくつのパラメータで優れているかを保存する変数。\n",
    "\n",
    "\t\t#チェックパラメータ変更ブロック\n",
    "\t\tfor index3 in range(len(target_para.index)):#今回は最小化。\n",
    "\t\t\tif float(line[1][target_para.iloc[index3][0]]) > float(translated_df.iloc[index2][target_para.iloc[index3][0]]):\n",
    "\t\t\t\tnot_pareto_possibility += 1\n",
    "\t\t\t\tcontinue #相手のパラメータの値が自分のパラメータの値よりも小さければ次のパラメータのチェック。\n",
    "\t\t\tbreak #自分のパラメータの値よりも相手パラメータの値の方が大きければその時点でbreakして次の相手との比較に移る。\n",
    "\n",
    "\t\tif not_pareto_possibility == len(target_para.index):\n",
    "\t\t\tnot_pareto_flag = 1\n",
    "\t\t\tbreak#相手がすべてのパラメータで自分自身に勝利していれば自分を変更する。\n",
    "\n",
    "\tif not_pareto_flag == 0:\n",
    "\t\tpareto_solution = (input_df[input_df.iloc[:,0] == line[1][\"index\"]].values).tolist()\n",
    "\treturn pareto_solution\n",
    "\n",
    "\n",
    "args_input = \"data_14/data.csv\"\n",
    "args_target = \"data_14/target_param.csv\"\n",
    "args_row = 1000\n",
    "args_result = \"result.csv\"\n",
    "\n",
    "judge_df = pd.read_csv(args_target, header=None, encoding=\"utf_8_sig\")\n",
    "if judge_df[0][0] == \"target\":\n",
    "    target_params = pd.read_csv(args_target, header=0, encoding=\"utf_8_sig\")\n",
    "else:\n",
    "    target_params = pd.read_csv(args_target, header=None, encoding=\"utf_8_sig\")\n",
    "\n",
    "input_data = pd.read_csv(args_input, header=2, encoding=\"utf_8_sig\", nrows=args_row)\n",
    "translated_data = translation_data(input_data, target_params)\n",
    "\n",
    "with Pool(processes=multi.cpu_count()) as pool:\n",
    "    output = pool.map(partial(main, target_para=target_params, translated_df=translated_data, input_df=input_data), translated_data.iterrows())\n",
    "\n",
    "with open(args_result, \"w\", encoding=\"utf_8_sig\") as f:\n",
    "    writer = csv.writer(f, lineterminator='\\n')\n",
    "    writer.writerow(input_data.columns)\n",
    "\n",
    "    for row in output:\n",
    "        if row == []:\n",
    "            continue\n",
    "        for cell in row:\n",
    "            writer.writerow(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library of extracting Pareto optimal solutions is pygmo.\n",
    "\n",
    "- [pygmo](https://esa.github.io/pygmo2/mo_utils.html)\n",
    "\n",
    "ndf, *_ = pygmo.fast_non_dominated_sorting(points)\n",
    "\n",
    "↑ If you write this code,\n",
    "\n",
    "points[ndf[0], :]\n",
    "\n",
    "↑ you can extract Pareto optimal solutions by writing this command.\n",
    "\n",
    "--\n",
    "\n",
    "\n",
    "パレート最適解を取り出すライブラリとしてはpygmoというものがある。\n",
    "\n",
    "- [pygmo](https://esa.github.io/pygmo2/mo_utils.html)\n",
    "\n",
    "例えば、\n",
    "\n",
    "ndf, *_ = pygmo.fast_non_dominated_sorting(points)\n",
    "\n",
    "とすれば、\n",
    "\n",
    "points[ndf[0], :]\n",
    "\n",
    "でパレート最適解を取り出すことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
