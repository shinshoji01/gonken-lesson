{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#pytorch packages\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "#To download the dataset for torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "#For plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will try to recognize hand-written digits, specifically the ones of the MNIST dataset, that contains overall 70,000 28-by-28-pixels pictures of hand-written digits. This dataset is easily accessible in pytorch via dataset.MNSIT. You just have to specify you want to download it if it's not already in the directory, and pytorch will process it to create a DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to the directory of your choice.\n",
    "PATH = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\train-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\train-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%C:\\tools\\IDEs\\Anaconda3\\envs\\pytorch_class\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "trn_set = datasets.MNIST(PATH, train=True, download=True)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data in the training set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\IDEs\\Anaconda3\\envs\\pytorch_class\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\tools\\IDEs\\Anaconda3\\envs\\pytorch_class\\lib\\site-packages\\torchvision\\datasets\\mnist.py:63: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_set.train_data), len(tst_set.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is represented by a tensor of size 28 by 28, each value represents the color of the corresponding pixel, from 0 (black) to 255 (white). Torch tensors are the equivalent of numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to convert a torch tensor to a numpy array via the .numpy() command.\n",
    "\n",
    "Conversely, you can create a torch Tensor from a numpy array x via torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.train_data[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then easy to see the corresponding picture via plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x155207355c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOTklEQVR4nO3dfYxUZZbH8d8RQVSIQWk7xCHbsxM1MSbTgyVZw0tYxiXIP2AwZkicsJFsT3xJBkPMGDZxfEkMMcuMGM0kPQvCbGYdRwHBxOyihMSQ6GipqIDvpgmNvDRRGSHKLHD2j75MWqx6qqm6Vbfo8/0knaq6p27fQ8GPW3Wfe+sxdxeAke+8ohsA0BqEHQiCsANBEHYgCMIOBHF+Kzc2ceJE7+rqauUmgVD6+vp0+PBhq1RrKOxmNlfSKkmjJP2nu69IPb+rq0vlcrmRTQJIKJVKVWt1v403s1GSnpR0k6RrJC0ys2vq/X0AmquRz+xTJX3i7p+5+98k/UnS/HzaApC3RsJ+haS9Qx73Z8u+w8x6zKxsZuWBgYEGNgegEU0/Gu/uve5ecvdSR0dHszcHoIpGwr5P0uQhj3+QLQPQhhoJ+xuSrjSzH5rZGEk/k7Q5n7YA5K3uoTd3P2Fmd0v6Xw0Ova1x9125dQYgVw2Ns7v7i5JezKkXAE3E6bJAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0dAsrmh/p06dStaPHz/e1O2vW7euau3YsWPJdXfv3p2sP/bYY8n68uXLq9aeeOKJ5LoXXnhhsr5y5cpk/Y477kjWi9BQ2M2sT9LXkk5KOuHupTyaApC/PPbs/+zuh3P4PQCaiM/sQBCNht0lbTGzN82sp9ITzKzHzMpmVh4YGGhwcwDq1WjYp7v7FEk3SbrLzGae+QR373X3kruXOjo6GtwcgHo1FHZ335fdHpK0UdLUPJoCkL+6w25mF5vZ+NP3Jc2RtDOvxgDkq5Gj8Z2SNprZ6d/z3+7+P7l0NcIcOXIkWT958mSy/s477yTrW7ZsqVr76quvkuv29vYm60Xq6upK1pctW5asr169umrtkksuSa47Y8aMZH327NnJejuqO+zu/pmkH+fYC4AmYugNCIKwA0EQdiAIwg4EQdiBILjENQf9/f3Jend3d7L+5Zdf5tjNueO889L7mtTQmVT7MtQlS5ZUrV1++eXJdceNG5esn4tng7JnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGfPwWWXXZasd3Z2JuvtPM4+Z86cZL3Wn33Dhg1VaxdccEFy3VmzZiXrODvs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZc1Druuq1a9cm688991yyfsMNNyTrCxcuTNZTpk+fnqxv2rQpWR8zZkyyfuDAgaq1VatWJddFvtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ5u4t21ipVPJyudyy7Z0rjh8/nqzXGstevnx51dqjjz6aXHfbtm3J+syZM5N1tJdSqaRyuWyVajX37Ga2xswOmdnOIcsuNbOXzOzj7HZCng0DyN9w3savlTT3jGX3Sdrq7ldK2po9BtDGaobd3V+R9MUZi+dLWpfdXydpQb5tAchbvQfoOt19f3b/gKSqX7JmZj1mVjaz8sDAQJ2bA9Coho/G++ARvqpH+dy9191L7l46FyfDA0aKesN+0MwmSVJ2eyi/lgA0Q71h3yxpcXZ/saT0dZAAClfzenYze1rSLEkTzaxf0q8lrZD0ZzNbImmPpFub2eRIV+v702uZMKH+kc/HH388WZ8xY0ayblZxSBdtqGbY3X1RldJPc+4FQBNxuiwQBGEHgiDsQBCEHQiCsANB8FXSI8DSpUur1l5//fXkuhs3bkzWd+3alaxfe+21yTraB3t2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfYRIPVV0729vcl1t27dmqzPnz8/WV+wYEGyPm3atKq1m2++Obkul8/miz07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBlM3B1brefe7cM+f0/K4jR47Uve01a9Yk6wsXLkzWx40bV/e2R6qGpmwGMDIQdiAIwg4EQdiBIAg7EARhB4Ig7EAQXM8e3NSpU5P1Wt8bf8899yTrzz77bNXa7bffnlz3008/TdbvvffeZH38+PHJejQ19+xmtsbMDpnZziHLHjCzfWa2I/uZ19w2ATRqOG/j10qqdBrVb929O/t5Md+2AOStZtjd/RVJX7SgFwBN1MgBurvN7N3sbf6Eak8ysx4zK5tZeWBgoIHNAWhEvWH/naQfSeqWtF/SympPdPdedy+5e6mjo6POzQFoVF1hd/eD7n7S3U9J+r2k9CFdAIWrK+xmNmnIw5sl7az2XADtoeb17Gb2tKRZkiZKOijp19njbkkuqU/SL9x9f62NcT37yPPtt98m66+99lrV2o033phct9a/zVtuuSVZf+aZZ5L1kSh1PXvNk2rcfVGFxasb7gpAS3G6LBAEYQeCIOxAEIQdCIKwA0FwiSsaMnbs2GR91qxZVWujRo1KrnvixIlk/fnnn0/WP/zww6q1q6++OrnuSMSeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJwdSZ9//nmyvmHDhmT91VdfrVqrNY5ey/XXX5+sX3XVVQ39/pGGPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME4+whXa8qtJ598Mll/6qmnkvX+/v6z7mm4al3v3tXVlaybVfxG5bDYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyznwOOHj2arL/wwgtVaw899FBy3Y8++qiunvIwe/bsZH3FihXJ+nXXXZdnOyNezT27mU02s21mttvMdpnZL7Pll5rZS2b2cXY7ofntAqjXcN7Gn5C0zN2vkfRPku4ys2sk3Sdpq7tfKWlr9hhAm6oZdnff7+5vZfe/lvS+pCskzZe0LnvaOkkLmtQjgByc1QE6M+uS9BNJf5HU6e77s9IBSZ1V1ukxs7KZlWudpw2geYYddjMbJ2m9pKXu/tehNXd3SV5pPXfvdfeSu5c6OjoaahZA/YYVdjMbrcGg/9HdT3+d6EEzm5TVJ0k61JwWAeSh5tCbDV4nuFrS++7+myGlzZIWS1qR3W5qSocjwLFjx5L1vXv3Juu33XZbsv7222+fdU95mTNnTrL+4IMPVq3V+ipoLlHN13DG2adJ+rmk98xsR7ZsuQZD/mczWyJpj6Rbm9IhgFzUDLu7b5dU7b/Yn+bbDoBm4XRZIAjCDgRB2IEgCDsQBGEHguAS12H65ptvqtaWLl2aXHf79u3J+gcffFBPS7mYN29esn7//fcn693d3cn66NGjz7YlNAl7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IIsw4e19fX7L+yCOPJOsvv/xy1dqePXvqaSk3F110UdXaww8/nFz3zjvvTNbHjBlTV09oP+zZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiCIMOPs69evT9ZXr17dtG1PmTIlWV+0aFGyfv756b+mnp6eqrWxY8cm10Uc7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAhz9/QTzCZL+oOkTkkuqdfdV5nZA5L+TdJA9tTl7v5i6neVSiUvl8sNNw2gslKppHK5XHHW5eGcVHNC0jJ3f8vMxkt608xeymq/dff/yKtRAM0znPnZ90van93/2szel3RFsxsDkK+z+sxuZl2SfiLpL9miu83sXTNbY2YTqqzTY2ZlMysPDAxUegqAFhh22M1snKT1kpa6+18l/U7SjyR1a3DPv7LSeu7e6+4ldy91dHQ03jGAugwr7GY2WoNB/6O7b5Akdz/o7ifd/ZSk30ua2rw2ATSqZtjNzCStlvS+u/9myPJJQ552s6Sd+bcHIC/DORo/TdLPJb1nZjuyZcslLTKzbg0Ox/VJ+kUT+gOQk+Ecjd8uqdK4XXJMHUB74Qw6IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEDW/SjrXjZkNSNozZNFESYdb1sDZadfe2rUvid7qlWdv/+DuFb//raVh/97GzcruXiqsgYR27a1d+5LorV6t6o238UAQhB0Iouiw9xa8/ZR27a1d+5LorV4t6a3Qz+wAWqfoPTuAFiHsQBCFhN3M5prZh2b2iZndV0QP1ZhZn5m9Z2Y7zKzQ+aWzOfQOmdnOIcsuNbOXzOzj7LbiHHsF9faAme3LXrsdZjavoN4mm9k2M9ttZrvM7JfZ8kJfu0RfLXndWv6Z3cxGSfpI0r9I6pf0hqRF7r67pY1UYWZ9kkruXvgJGGY2U9JRSX9w92uzZY9K+sLdV2T/UU5w91+1SW8PSDpa9DTe2WxFk4ZOMy5pgaR/VYGvXaKvW9WC162IPftUSZ+4+2fu/jdJf5I0v4A+2p67vyLpizMWz5e0Lru/ToP/WFquSm9twd33u/tb2f2vJZ2eZrzQ1y7RV0sUEfYrJO0d8rhf7TXfu0vaYmZvmllP0c1U0Onu+7P7ByR1FtlMBTWn8W6lM6YZb5vXrp7pzxvFAbrvm+7uUyTdJOmu7O1qW/LBz2DtNHY6rGm8W6XCNON/V+RrV+/0540qIuz7JE0e8vgH2bK24O77sttDkjaq/aaiPnh6Bt3s9lDB/fxdO03jXWmacbXBa1fk9OdFhP0NSVea2Q/NbIykn0naXEAf32NmF2cHTmRmF0uao/abinqzpMXZ/cWSNhXYy3e0yzTe1aYZV8GvXeHTn7t7y38kzdPgEflPJf17ET1U6esfJb2T/ewqujdJT2vwbd3/afDYxhJJl0naKuljSS9LurSNevsvSe9JeleDwZpUUG/TNfgW/V1JO7KfeUW/dom+WvK6cbosEAQH6IAgCDsQBGEHgiDsQBCEHQiCsANBEHYgiP8H/v1TaABfc0YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trn_set.train_data[0].numpy(), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the corresponding label..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\IDEs\\Anaconda3\\envs\\pytorch_class\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pytorch neural network will expect the data to come in the form of minibatches of tensors. To do that, we use a pytorch object called DataLoader. It will randomly separate the pictures (with the associated label) in minibatches. If you have multiple GPUs, it also prepares the work to be parallelized between them (just change num_workers from 0 to your custom value). We only shuffle the data randomly for the training.\n",
    "\n",
    "First we need to explicitely ask our dataset to transform the images in tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfms = transforms.ToTensor()\n",
    "trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at an example. A data loader can be converted into an iterator and we can then ask him for a minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a minibacth containts two torch tensors: the first one contains the data (here our pictures) and the second one the expected labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_example[0].size(), mb_example[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pytorch has automatically added one dimension to our images (the 1 in second position). It would be 3 if we had had the three usual channels for the colors (RGB). Pytorch puts this channel in the second dimension and not the last because it simplifies some computation.\n",
    "\n",
    "Let's see the first tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 0.2510,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000, 1.0000,\n",
       "         0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.2510, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.2510, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5020, 0.0000,\n",
       "         0.7490, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.7490, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000,\n",
       "         0.0000, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.5020, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000,\n",
       "         0.0000, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000,\n",
       "         0.2510, 1.0000, 1.0000, 1.0000, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.2510,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490,\n",
       "         1.0000, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000,\n",
       "         1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000,\n",
       "         1.0000, 1.0000, 0.5020, 0.0000, 0.2510, 0.7490, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.7490, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5020,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.7490, 1.0000, 1.0000, 1.0000, 1.0000, 0.5020, 0.2510, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_example[0][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pytorch transformed the values that went from 0 to 255 into floats that go from 0. to 1.\n",
    "\n",
    "We can have a look at the first pictures and draw them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    sub_plot = fig.add_subplot(1,4,i+1)\n",
    "    sub_plot.axis('Off')\n",
    "    plt.imshow(mb_example[0][i,0].numpy(), cmap='Greys')\n",
    "    sub_plot.set_title(mb_example[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another usual transformation we do before feeing the pictures to our neural network is to normalize the input. This means subtracting the mean and dividing by the standard deviation. We can either search for the usual values on Google or compute them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1307), tensor(0.3081))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.mean(trn_set.train_data.type(torch.FloatTensor))/255.\n",
    "std = torch.std(trn_set.train_data.type(torch.FloatTensor))/255.\n",
    "mean,std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide by 255 to get the means of our data when it's convereted into floats from 0. to 1.\n",
    "\n",
    "Then we go back to creating a transfrom and add the normalization. Note that we use the same mean and std for the test set. Afterward, we reload our datasets, adding this transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean,), (std,))])\n",
    "trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to plot our digits, we will have to denormalize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABnCAYAAACjHpHIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAq3klEQVR4nO2deXCb553fPy/uGwRAguB9iZJFS7Kk2LLqyGdlx5vEsb3bbNtJd3c6m+Of9o9Ou+1OZ2e6nbSz26bTf7bbaXcy3XR2O5PpdpptG1uOrThtDjuxrEiiDkoyxUMECQIgQdw38PYP8nkCUpSpgyf0fGY4oojrxQ8vvu/v+V2Ppus6CoVCodgeDDt9AAqFQvEooURXoVAothElugqFQrGNKNFVKBSKbUSJrkKhUGwjSnQVCoViG2lq0dU0bUTTtI81TdPu4b5HNE37YDuOq1lQ9t06lG23jp227aaIrqZpU5qmnd6M59pkvgn8O32lGFnTtOyan5qmaX8CoOv6KJDUNO21nTzg9dhD9v0HKydzSdO07zTecbfad6/YFkDTtL+jadqYpmk5TdNuaZr2LCjbPgBrz9uDmqa9r2laStO0cU3T3hR33ArbNqWnq2maSdO0DuBF4K/F33Vdd4kfIAQUgL9qeOh/A76xnce6F7mbfYE54F8B/+UuD1X23YC72VbTtJeBfwP8fcANPAdMNDxU2XYD1rOtpmkm4H8B3wf8wNeBv9Q0bX/DQzfXtrquP9QP8BdAnWUBywL/FDgJfAAkgUvACw33/78sX2l+BmSAd4HWldtswF8CiyuPPQe0r9zWCfxvIAGMA19reM4/BP7HymPTwFeB3wbOfspx/w7LJ63W8LeulfdhfVi7bNbPXrQvy8L7nXX+vqvsu5dsu3JMv/sp70XZ9gFsCxxaOb5GHXgX+OZW2XazDDwFnG44wEXg8yx70i+v/L+twbi3gP2AfeX/f7xy2zeA/wM4ACPwGcCzctuPgf+48gEcBeLASw3GrQBvrLymHfgW8KefcszvA3+4zt/TwJGdPmn3sn25i+juRvvuBduuPF8Z+H2WhSUM/AfArmz70LZdT3TfA763VbbdivDC3wPe1nX9bV3X67quvwd8zLKxBX+u6/pNXdcLwH9fMRYrBgoA+3Rdr+m6fl7X9bSmaT3AZ4F/put6Udf1i8C3Wb5qCT7Udf2vV16zALSwfMW8A03T+oDngf+6zs2ZlcfuVna9fTdgN9t3t9q2HTADfwt4duU1jwF/sOb4lW3v37Y3gBjwe5qmmTVNe4VlbXCsOf5Ns+1WiG4f8GVN05LiBzgFdDTcZ77h9zzgWvn9L4AfAN/VNG1O07R/q2mameUlRELX9UZjTbN89RTMrDmOJZZjX+vxW8BPdV2fXOc2N8tLmN3KXrDvp7Gb7btbbVtY+fdPdF2P6Lq+APx7VgsWKNvCfdpW13XhCX9h5fX/McuCH17zuE2z7WaJbuOoshngL3Rdb2n4ceq6/scbPomuV3Rd/5e6ro8AzwBfZPmqNQf4NU1rPBF7gdm7HAPAKMtLlfX4bdbxcjVN6wIsLF/9dhN7zb7rskvtu+ttq+v6EssioN/tMcq2kvs+b3VdH9V1/Xld1wO6rn8OGAQ+Erdvtm03S3SjLB8oLAetX9M07XOaphk1TbNpmvaCpmndGz2Jpmkvapp2WNM0I8sxlApQ13V9huUA/B+tPN8R4HdXXutuvAcc1zTNtuY1nmH5SvhX6zzmeeB9XddLGx3rNrMn7LuSHbaxHHcTx2ZqeMxutO+esC3w58A/1DQtqGmaD/hHLGfcBcq2D37eHll5vEPTtH/Csvf9nYbHbKptN0t0/wj4g5Ulw98GXgf+OctB7Rng9+7xtUIsZxvTwBjw/1heWgD8XaCf5avb94B/oev62bs9ka7rUZaTZa+vuel3gP+5Zkki+Arwn+7hOLebvWLfP2B5Kfz7LMfwCqyOO+5G++4V236T5az9zZXnvwD864bblW0f3La/BURYju3+TeDlNQK7qbbVdL15h5hrmjbCchjhhL7BG125Sv5nXdf/xrYcXBOg7Lt1KNtuHTtt26YWXYVCodhtNGVHmkKhUOxWlOgqFArFNqJEV6FQKLYRJboKhUKxjZg2uF1l2TZmw5mcn4Ky78Y8qH2VbTdG2XbruKttlaerUCgU24gSXYVCodhGlOgqFArFNqJEV6FQKLYRJboKhUKxjSjRVSgUim1ko5IxhUKxyegr27bkcjni8TiVSoVqtUq1WsXtdtPe3o7ZbMZoNGI0Gnf6cBWbjBJdhWIb0XWdWq2GrutMTk7yne98h0QiQSqVIp1Oc/z4cb72ta8RDAax2WwYDAY07WFKwRW7DSW6CsU2IKb51et1qtUq9XqdZDJJOBxmbm6OeDxOJpMhFApRKBTkfRTNhxJdhWKL0HWder2OrusyfFAoFLhx4waRSISPP/6Yq1evkkqlZIihXC5TLBYpl8vYbLaNX0Sx51Ciq1BsEUJ06/U65XKZXC7H4uIiP/jBDxgbG2NiYoLJyUnK5TIWiwWj0SgFt1KpKE+3SVGiq7gDIRK1Wo1KpUI2m0XXdaxWKyaTCbPZjMPhUEmeDajX65RKJarVKgsLC8RiMebn54lEIsTjcbLZLLVaDQCTyYTVasXhcGC327Farcq+TYoSXcUdVCoVpqenWVhY4OLFi/z4xz+mXC4zNDREV1cXIyMjnDp1CqfTudOHuqsplUrMzMyQTCb54Q9/yI9+9COy2SyRSIRcLicvbAaDgZaWFgKBAJ2dnXR0dOD3+zEajSqJ1oRsmehu9TZA6mTcOkSS5/bt21y7do0zZ85QKpV4+umn2b9/PxaLhZMnT+70Ye56arUaS0tLxGIxxsfH+eCDD6hUKvL2xu+I2WzG6XRKT9disezEIe9JHkRrdlI/NlV06/W6jEVFo1GuX79OqbT5O0L7fD4OHTqE2+1e9XdhSE3TVKnNA1Cr1ajVahQKBcbHx7l8+TJzc3OyxGlubg6j0UhHR4dcFitWU6/XKRaLlEolIpEIP/3pT5mbm2N8fFzZbBNp1JpMJkMqlaJcLpNIJCgWizIpqeu61AGv10tHRwc2mw23243T6UTTNEwmEwbD9vWJbbroFgoFisUiZ8+e5Vvf+hapVGozXwKAo0eP8s1vfpORkRFgtdgKwd1OIzYLtVqNcrlMOp1mdHSUn//850QiEarVKrVajUgkwsLCAr29vZTL5Z0+3F2JWCXEYjFGR0d56623GB8fJ5fLqcTYJiKcg3K5zPXr1/nFL37B4uIio6OjzMzMkM/nyeVy8kJnMBgYHh7m137t1+jq6uLIkSMMDg5Kwd2zolur1Uin02QyGZksSKfTm/kSAMzOzjI/P09HR8cqwTWZTDLRo2majIkpj3djRKZdJM/y+TypVIpisSiXb9VqVZY/KVYjqhSq1SrpdJpoNEo0GiWRSJDL5ahWq7LLzO12Y7Va5cXMYDDQ2tpKS0uLKhPbgFqtJhO9qVSKQqEg9SCZTDI3N0csFqNQKJDL5eS5q2kaLpeLaDQKQHt7Oz6fD5vNJnVju9jUV8rlcnz3u99ldHSUTz75hFKptCWCF4lE+LM/+zPa29ulqJpMJtra2vD5fAwNDXHy5ElcLpcUYcXGVCoVkskkCwsLzM/PMzMzQ6lUUh7aPVAqlUilUmQyGb7//e/z0UcfEY1GiUQilEolPB4PTqeTnp4evvCFL7Bv3z6SyaRsA4blC9/hw4dVPPcuCKcunU4TDof5/ve/TywWIxKJEA6HKRaLLC4uyvCCQGjQ4uIiP/zhD3G73Vy6dIlQKERPTw9f+cpX6Ozs3Lb3semi+7Of/Yy33noLYMu8zFQqxZkzZ+T/NU3DYrEwPDxMX18fCwsLjIyMYLVapSArb3djGj3chYUFksnkTh/SnqFSqZBIJGTFx5kzZ+SqAZYTZYFAgL6+Pl588UWGh4dJp9PMz8/LkE46nSYUCqnQ2F3QdZ1MJsP8/DyXL1/mrbfeYnJyUsZvBZqmrfJwxb+ZTIbr168DcO3aNVwuF0ePHuW1117bu6JrNBppaWmhra2NYrFIPp/fMLNoNBplTaJY3ool7P0kHnRdlydxW1sbMzMzVCoVgsEgVqv1Yd/aI4HIoIvP0OfzUSqVKBQKckiLrusUi0USiQQOhwOLxSIvbo8ajfXMkUiEc+fOEY1GZfLRYrHg8/mwWq08+eSTPPbYY3R2dtLa2orZbMblctHa2kqtVsPj8VAul/H5fKo+l9WNJcVikXQ6TbFYZGxsjPHxcSYnJ0mn09TrdQwGg6z4aGtrk6WMYs7F4uKivK9YuVWrVUqlEsVicdtXcpsqumazmZ6eHp544glu377N1NTUhvE/o9GI3+/H6XRSLpdlMXk6nb4v0a1Wq8RiMRKJBKVSCZ/PR0dHB6dPn8br9aoTeQM0TcNqtRIIBKjVavT09LBv3z5isRjhcFjG0nRdZ35+nkuXLpHJZOjr6yMYDD6SolutVkkkEmQyGc6ePcu3v/1t4vG4zKR7vV6OHTuG3+/n13/913nuuecwm82yycRqteJyuQDkF99gMKhwGMuCWS6XqVar3Lp1i/fee4/FxUUuXrzI2NiYDOeIyWxut5tAIMCpU6ek1yochIsXLzI6OkqhUKBSqVCr1SiVSlQqlfvWmc1g0z1dj8dDa2srqVRqw9iUruvSu/J4PJRKJUwmE5VKhVKpJL1e8e9GlMtlGWBPJBKYTCYKhcJmvb2mx2AwYDQasVgs2O12nE7nHV6s+DIkk0kymcwjWcUgPP56vU4ulyOZTBKNRpmamiKZTGIymTAajdjtdvx+P62trXR0dNxx8VdhhLuj6zqVSkWeazMzMywsLHDz5k1mZmYAZFmozWbD6/USDAZpb2+nq6tLPkc+n2dqagqXy7WqfKzxM9zqnoK1bKro2u12XnnlFY4dO8b58+cJBoPk8/k77lev1+UoO6/Xy+HDh/H5fPL2arVKNBplcXGRpaUlGSSvVCqrissVm4sotzMajTIB2VhOI07OUqlEJpNhcXHxkfs8xBc5m82ytLTEmTNnmJyclDXpFouFffv20dvbS39/Py+99BLt7e309PQokb0PSqUSo6OjTExMcPXqVX75y1+ytLQk8wxWqxWv14vNZuPll1/m1KlTtLS00N/fv6p+v1wuY7fbCQaDzM7OSo/Z5XLhcrkIhULbnrjcVNG1Wq0cPHiQ/fv34/f7yeVydxXdeDxOLBbD7/czMjJCZ2cnZrMZi8VCpVLh1q1bxGIxYrGYLDsTBdGKrWOt8K4XlqlUKrIgvVKpbLunsJOI4eOzs7NMTU1x5swZzp07J1dZdrudkZERDhw4wP79+3nmmWfweDxYLJZHMgTzoJRKJX7yk59w/vx5JiYmuHHjhmx2gGWt8fv9+P1+nn32WV5//XWpH43nrNALv9/P6OgoH374IUtLSzidTtrb2wkEAtseetxU0RVfWACPx8PQ0NBdRVe0O7rdbvx+Px6PB4fDgcPhkJ1Rbrcbk8mEx+OR05fuBZHgKBaL8nFCQJS3cXfERa1YLJLNZkmn0+Tz+TsSDWazGbfbjdfrlTXRzU5jB1QikWBqaoqpqSmWlpbkGMZAIIDb7aazs5Pu7m46OztlHeijeN6JRNiDdIjW63XS6bSs9Rc14iLm3dLSwqFDh/D5fHR3d8sa6LWvczcHwuFw0NXVhd/v3/YY+qaLrslkQtd1uru7+dKXvrRukFrXdeLxONFoFIPBgMvlkob0+XxomsbIyAjVapWbN29y+/ZtKcSNBc93o1QqMT8/Lz3m/v5+HA4HHo9HVTLcBZF0WFpaYnZ2Vi7rRGwdfnVRDQQCjIyM0N/fT0tLyyMhuqVSiVgsRi6X45133uHs2bMkEgkmJyepVCpyCJDf7+e5556jt7cXh8Mha8UfBRs1ImL/pVIJo9EoLz73SqVSYXZ2litXrshzUDQ42O12Tp48yTe+8Q06OjpkhdJGJaoijguwf/9+PvvZz9Lb27vtg5s2vQ1DvHG73Y7dbl/3PrquY7FYVsVSNE3D7XbjcrlWeQXZbBa3243D4bjnD61arZLNZjGbzaRSKbLZLIDMFCvWp1KpkMvl7lqnKz5bm82Gz+fD6/U+MoX8ojB/aWmJyclJzp07R6lUolQqoes6Pp+PgYEBmchpa2vDaDTKuPiD0uhg7DXhFm3lZrP5vkNQIkm5tLQk/9aY5A0EAgwODhIMBu8aBmtk7et7PB66uroIhUJ729O9HywWC36/X/5flCxtxolVLpeJRqPkcjnm5uaIRCL4fL5Vr6dYjUgQzc/PEw6H1w0LCU9XZIs9Hk/TlzeJ7HY2m+XKlSuEw2HC4bCMFYoQ2MDAAJ/5zGfkeSaE4F7P58YdJkTSWIR4ABmrtNlsOJ1O+ftuXrmZTCbsdvumhPXut9FKhDYqlQqRSITR0VGmpqYoFosA3L59m/PnzxOPxxkZGaGlpeWhju9+2BHRFZ7w2j7zzepgE+EFk8nE5OQkly9fpqenh/7+/od+7mYmnU5z9epVwuHwujMzGlcxfr8ft9vd1LMtRLlirVZjYWGB999/n4mJCSYmJsjn89Jx8Hq9PP744xw5cgS73b4qrngvtml8nWKxyPT0NJlMhtHRUa5cuYKmafh8Pux2O11dXRw4cACHw0FfX9+uFV3RJSpi/g9zjjQ+9l7tKhogisUiV69e5cMPP2R+fl42bN28eZN4PM6xY8d47bXX6OjoeODju192zNMVH0RjrZy4OjWSz+dlQfO9LlGExyAyzel0mmQySS6Xu2v8RgTcxRW5WYXk0yiXy2QyGfL5/B1JSxGvF2GhRyEpKc6jcrksvc5EIiETszabjVAoRFtbG4FAALPZfNcQWGNH39rzXQhEtVolk8mwsLBAIpFgcXGRTCYjVxiiJM3n8+HxeGT3VeNwp93Ew4rteuWKwl75fJ5kMim9/bV2Fx1nYoskYUuR2BMXuj1fp/sgiK4e0fMfj8dXdbGNjY0xNTVFPB6X7aj3Sr1eJxwOc/36debn52WCbz0CgQDDw8My4N/sy+a16LpOKpXik08+YXFx8Y7wgsFgoL29nfb2djo6OrZ1KtNOUa1WmZ6eZmJigkuXLjE2NkY0GsVsNhMKhRgaGuI3f/M3OXDgAL29vZ9qE1FSVqlUpH3n5uYYHR2VA1rE7ItoNEqpVMLlcuHxeAAoFApks1lisRgXL17EZrPx6quvcvToUZxOJ62trU0VXxdhLLfbLRNyYnZuoVDgZz/7mexGWxvT1TRNXsRKpRJXr16VMxrEtlMdHR0cPHiQ/v7+bZ/stuPfnFqtJgeFTE1Nce3atVVeVjweZ25ujlwu90AD0ZeWlpiYmMDlclGpVOTAi7UMDg7S3t4uPYZHMeMspjctLCzI2JdAtGv39vbKrWSanXq9zszMDB9++CFTU1PMzc2RSqXo6Oigra2Nnp4ennnmGfr7+z81mSO8qkKhQD6f5/bt28zPz3PhwgXefvttORdAZPzFnnQnT57kySeflDHlQqEgB6KbzWaCwSB+v1/OyWgmNE2TLdO6rkvRFeflJ598wvj4uLz/2gE3jX8TfzcYDDLkIboE29vbmzuRJqYuCeOJQcM3b94kGo0yOzvL7OzsqgaIxcVF2TN9v4MpRCthMpmkXC7jcDjI5XLr3lfTNMbHx2ltbSUUChEIBGRsrpnFV2SYK5UK8XicpaUlWRcJv1oiirkaAwMDdHd3PxKiC8hWVOElieoNEdNeL9TSmMTJZrNyR4OFhQXZ1lqtVgmFQrzyyiuywaQxkQYwMDDA8PAwgJxtPDk5SS6Xk5/X+fPnpcMANM0qTTRaFYtFZmdnGR8fl+GCtc7Xeqvf9f5mtVppa2vD4XBw4MABjh49SldXFw6HY8vex3psq+g2Lq0uX77MhQsXyGazzM7Orprj2ljbK07C9eK994KIUWqaxszMzF3FIhAIMD8/j8/n4/XXX+eZZ56Rw42bWXTL5TKRSIR0Os2NGze4ffs2+XxentiiGN3tdnP48GFOnz5NMBhsii/23WiMHwrHoFAoyPMvEAjQ29tLV1eXFN7GHIXIQcRiMc6ePUskEmF6eprJyUl8Ph9Hjhyho6ODEydO8JWvfGVVWKCxlrQxRiw8YVG3KkZInj17lhMnThAMBunu7iYQCODxePb8OWu323nzzTd5/vnn+fjjj3nvvfeIx+OMj48Ti8XuSK41zlVo/Jv4HZbLxJ588kn8fj+vvfYap06dkt70drItoivevGhuyGQyhMNhmQWemZkhk8mQyWRYWlra1Kk/IrYD3LFkbqRWqzE5OSkTGeIkb/YWV7HqEC3bYgsUITBiWWY2m/F6vQQCAZxO5yORRBMCWiqVVu23Jcq2ROnWWluIxFg+n2d2dlaWmU1NTZHP5xkZGZHDoQKBwH3FYkVIQXh94XCYUCjEwsKC7OxcK0B7EYPBIMdi9vb2ypVnLBaT4ZfGHU3W04y1eybabDY5tjQYDOJ2u3dkxbbloitmWFYqFebn53nvvffk7qjXrl2jWCySyWTkyb1TuxSUSiXC4TDJZJJEIrEjWc2dQpQriZ/G9y6y9G63m66uLjo6OmTLZbMi5jqXSiUmJia4ePGibPc1Go2EQiGGh4fp7++/QzDFDsDxeJzZ2Vk5fvCpp57ijTfewOv1Mjw8jNfrfaDZuYFAgC996UtEo1Gq1SrhcFiOP6zX63IQDGzdJgLbgdFoxOFwYLVaOXLkCF6vV17ElpaWyGazsgTs0qVLXLlyRVYmCHRdx2g00traisfj4fjx47z22mt0dXXR09OzY7bZctHVdZ1CoUA6nebmzZu8++67jI+Pk0gkSCaTUmR3WuBEba/FYmFpaemR8HLhV0kesSJYG8YRJ7/H46Gzs1O2/e7VL/O9IDzVQqHA7du3uXTpkjwfxMzhgwcP4vP57qhYqNfrxGIxLl++TCwWk6J74sQJnn/+eRlzfdD9+4R45HI5Ll26JOdQT01Nkc1mVwnKXr4wCs8UfjUnoXHGbiqVkqGGer3OtWvXpLPQGFoQ+88NDg4yMjLCM888g9/v39FzeFvCC42eQzabJZfLyYn7u4nGGspHQXABWYYjSvLWrjRE8iEYDGKz2ZpecAWNNbVrB4zbbDbZ5r5emEUk0Or1Ol6vF13X5XAgo9H4UDXOQkytVivBYJChoSGcTqdMEGezWTmn4H6HzOw21jZC6Louhwc5nU65UnA4HHd9n8LTbW9vlzt27HRobFs8XVGDmMvliMfjJBIJtaPsLiGXy/GLX/yCqakpxsfH7xDd7u5unnvuOVnRsZe/xA+DEFu32y1rlR0Oxx3epNjHKxKJ4PV6OXXqFB6Ph4GBAfmFf9iGAZHEfPbZZ3G73dy+fVsm7Pr7+zl8+LC8IOy0wGwmjQO1XC4Xw8PDlMtl+vv7MRqNVCqVVUItVibHjh3jpZdeoqura1fUMm9bIk2UJuXz+U9NaO00j5qoiFh7OBwmkUisOxiks7OTrq6uR3p78Ma2VqfTKeONa0VNTGvL5XK0tLTIkIzL5dqUrrG1u18fPnwYgEQiIXdXKBaLcjZDsyHsLYbfWCwWvF7vqhVYYzWD0WgkGAzS19dHS0vLrgi5bIvoNmbAHQ4HNptNLtvuZzseQWNLZWOpzr1iMBhkKZj4aW1t5emnn8bv9/P000/L+stmFGFRbF6pVFhYWJA10mIaWyMiMfOo7zMnYrmtra0EAgHZubj2/BCjL/v7++nq6pLVHpvtYWmahtPppK2tjd7eXvr6+mRCOhwOy1kNu3U2w8NSLBaJx+NkMhkmJibuiOf6/X66u7vp6OhgeHiYtrY2bDbbrvD8t1V0LRYLHo9HtvaJUo+HEV3gjqzlRoiYmLgQGI1Gjh07xte//nVZntLM8UsxIDqRSHDz5k1u3rzJrVu3KBaLd3wO4ovt9/t3xdJsp7Db7fT398tOJpvNtu5F2WAwEAwGOXr0KH6/n/b2diwWy6bXe2uaJr3tcrnM4OCgHNx/7tw5Ojs7CQaDTTvONJPJ8M477zA9Pc2FCxdkuFIIb3d3Ny+++CLt7e0cPnyY1tbWXRPj3nLRFS6+KLDv7OyUiQbRWQPIjrOtrGYQImq1WmlpacFkMknPWwTafT7fqmL3ZkQsgcV8WDHgpjGx2bg6sdlsWCyWXeEl7CQiRrrRuWG1WnG73avGGm72udQ45EYU+NvtdjmiM5fL7bpE9WYgnC3RIBKNRkmlUnfohajJ9fv99z1AfavZ8iMRO0PYbDYcDgehUIh8Ps/4+DjT09OkUikuXLhAJBKRsbDG1tSNEOJwL8fhdDoxm80cOXKEU6dO4fV66e3tJRgMyt/FxKJmFVxYriWdmpriJz/5CVNTUywuLq5qiDAajbhcLpkh7+jowOfzNXUX2kaUy2UWFhbQNE3uDbdeJYLRaKSlpUU2TmxlmEqc+2I7d6vVSq1Wkw7NTtW8bxVCbKvVKrFYjKtXr3Lt2jU5zAp+5ViFQiGOHDlCKBTadd7+tni6IqAvdt+s1WoMDAwwMTEhC8hhub9c1EiK2tGNnnu939dDJBbsdjsDAwO8+OKLBAIBuru7m6Jt8n7QdZ3JyUlGR0eJRCKyzEggynCcTqeM54ptZx5VarUaqVQKk8lENpuV5+baC75Y9m8HQmCE8IrMfqlUkq3zzYSohCoUCiwtLTE+Ps74+Lh0zhq/w263W7ZF77aw2I4NMRexQqvVyvHjx+nq6mJubo6xsTEpAvc7VUx4qGJJ3PiFsNlsDA0N4fP5GBwclD3qze7VroeYWiUG3Kz9ctpsNg4cOEBHRwf9/f3Y7fZHbjfbRkEzGAzUajXy+Twmk4mZmRnm5uZwOp07spusQHQPipbgfD6P2+2mpaVFhs+aAVEvXavV5IyWqakpuSoWOSG73U53d7f8josVx26zw44cjcFgkLv/1ut1Dh48SLVa5erVq3zve99jYWGBjz76SHrA94KI1VqtVlwuFwMDA6s8Do/Hw1NPPUVvby/9/f309/c3fTvr3ajX60SjUS5fvizbrxtpaWnh1Vdf5TOf+Qw9PT3yC/yoxXRFaZbJZKJarRKPx0mlUnzwwQcUi0X6+/v5/Oc/LysEtvOiJOZClMtllpaWiMVihMNhenp6GB4eJhQKNU3JmJjYVi6XuXz5Mj//+c+Znp4mHo/LPepg+bx94403GBkZ4dChQ3R2du7K7/iOXQLEySzQdZ1QKERLSwulUumBSl1EDM3lchEIBFaJrojZiiXHetPmHwVEIkIMxRbeUiNiR4SOjg68Xu89bfzXjIhklcVikRenarUqp4aZzWaKxSK1Wm1bdxxpHAMpQgmlUol8Po/BYMDr9eJwOJrmItk4KlNcXGKxmBRcIbpWq5VQKCRXsqJqZLex+47oAREJjFAoxL59+/jc5z5HKBSSt4sPRBS2N8sJeT8IbyGdTsuW38asr9VqlVlfr9eL3W5/JJNn4gLjcDgYHh7m2WefZX5+nuvXr1MsFpmbmwOWW277+voYHBwkFArJIfibvZVRYy27yHVUKhVu3LjBlStXmJ2dZXFxEZPJhNfrpaOjQ4bOmoFyuUw8HieZTHLt2jWuXLkiBxDBcreg2WyWtbkiebZbw2HN8amwHLJoa2ujr6+PQ4cO8fLLL98xTb+xY2W3fiBbSaVSIZVKkUgk5Hi8RsQuv62trVJ0H8WYt4jjWq1WDh06RCqVYmJigqmpKQqFApFIhGg0yvT0tNzG6IUXXuD555+XO1pvtuiKYURiH7tcLsc777zDmTNnqFQqVKtV6XgEg0EcDkfTiK7YbWNubo5r165x4cKFVc1RVqsVh8OB3++ns7OTtra2XV3i2ByfygqiHtJoND6yS+JPQySDRH1049JMJCDFIBer1SrLnR5VNE3D4/HQ3d1NNpulra0NQC7nK5UKiUQCo9HIzMwM8XhclkaKOQtC+BprfMVzr30t0U3VuB27EFtRS10oFEgmk3Luczqdxmaz0dXVhcvlkoKz1y+W4v3XajUymQyzs7Ny2H5jpY3BYMDv99PX10dfX5+sstmtggtNJrqKTyeXy3Hr1i3C4TDxePyOaWput5u+vj453EYMK9/LX96HwWQyMTQ0RHt7O/v27aNUKhGNRrl+/ToTExPUajUuX76M2Wxmbm6OGzduyK18RF5haGgIh8NBS0uL3LJ+bd2umOsgEnZiB+xwOMzY2JgcVp7JZEin08TjcTlbNplMMjIywptvvsnQ0BADAwN4PB65u/VeRcRvs9ks586d4+2332ZhYYFPPvlklaNgMpk4ffo0v/Ebv0EgEKCvr2/Xd5Mq0X2EEMNtYrEYuVzujo377HY7Xq9XdlPttvrG7UY09tjtdmq1GoODg3Le8u3bt6lWqywsLMiGhPn5eex2O6FQCI/HI3MKgUBADtQW3ZmNnlijRyx28igWi0xPT/Pxxx+TyWSYnJyUW7OLLa1EtY7D4eDxxx+nr68Pr9fbFOV99Xpd7g5+69YtfvnLX5JKpUin0/I+uq5jMBjo7e3liSeewG6374mwyu4+OsWWI1p9LRYLQ0ND8svbLOVGD4PwloxGI263myeffJKhoSE8Hg+tra1kMhnGxsZIpVIYDAYZa61Wq3LGba1Wk8v+UCgku8dEIwMsJ+5EDF14sNlsVnrUlUoFk8lEe3s7Ho9H7sY8ODhIa2srQ0NDhEIh3G73nk98ipBCNptlbGyMGzducOvWLbLZrKwUgeUSUDEnRZSH7oZZufeCEt1HHJPJJPf7OnjwIK+88gotLS3bvkPqbsVoNMoh5MePH6der/PYY48xPT1NOBzmvffe49atW0SjUSKRiGxRbSw3Ex1+Yk8uEUpobLv2+XxSqMPhMPl8nmw2SyaTweVyceLECdra2uScBYfDwbPPPsv+/fux2+2yTXsvh4NE7XGhUGB+fp533nmHDz/8UCZ/xY7MsLxX3OnTp+no6OCJJ57A5XLtmfe+46LbOKG/UqnIn2Yc1rEbEVl6u92Ox+NpuhrPzUAIqNFopF6vyw0ldV2nra2NYrFItVolkUisiiWKJFBja65YWTQmfY1Go4zl5nI5ksmk3C9QfDZerxe/3y8F1+l0EgwGaWlpkSVTezmGK6hWq+RyOdLpNMlkksXFRWlfEU4wm814PB6CwSCdnZ0y97BXztkdF91qtUoymSSfz3P9+nUmJyflnEzF1uNyuThw4ABtbW2y9Xdt44riV2iahsvloq+vT+7Mm8lkuHLlCh999BHFYlGK7tLSEjdu3KBYLOJwOKQ3JgRXbCNjMpmkR1yr1SgUCrJZqLu7G5fLxf79+/F4PKsqc8TM3L0kOJ9GvV5ncnKS999/X44EyGQysoLDZDLR2dlJa2srJ06c4PTp07S3t8t9+/YKO/7NqtVqLC4uyj3tp6enWVxclHs+KbYWm81Gd3c3bW1t8gveDB7TViEGONlsNunx1ut1QqEQuq6vOm9FiVMikcDj8eDxeFY9TygUYmhoaN3uS6PRyPHjxxkeHpat7WsTZHtJaO4FMYjp3XffJR6PMzc3R6FQkLeLnZgHBgYYHh5meHh4Tw6r2nHRFbNdxTi6bDZLoVBQ4QXFnkB4mE6nk/37968SCZHwyufzUqgFmqYRCATo7e1dt0pEbKgoGlQedPfgvUC1WpW1z2I+rkhICkR52MDAAAcPHmRoaGjP1iLvuOjW63UWFxeZmJhgbm6O+fn5O0YNKhS7kcYpZK2trZw8eXJVGZ7oIKvX6+smeUSo4G7P3Si2zbp1FCx3nF29epV4PM758+eZmpqiWCzKNl/xvp1OJy+88AKvvvoqTqdzz25FtOOiK4aviA0rS6WSNPa9IGocRUa48URV3IkQirWjC/dK5ne3IWwmNklU3D+VSoVoNMrMzIzcyUTsJCMQHZOhUIjW1tZNn2+xney46D4IjRngkZERTp48idvtlh+IGNuoWI3Y58vpdLJv3z7m5+d57LHHOHjwIO3t7fh8PiW8im0nm83ywQcfMD09zdjYmNw/sbGkTlRxiPm4e9lJ2LOiK2YDPPXUU3z1q1/F4/FgNptXbV2iWI1Imnk8HgYHB0kmkwwMDHDs2DE55GavnsiKvUsymeRHP/oRV65cWSW2IlQjdhH3eDxy8t1ePk93XHTFQHPRsbN//35ZoycSauVy+Y6JWGJpLDK7jVdAFV5YH4PBgM1mo1ar0dnZyeLiIl1dXXI7HrU6UOwEoo5ZDNMX8WyPxyN3EBdbazkcjj3/3d5x0TWbzTz++OMMDAxw8uRJ3nzzTdLpNGfOnOH8+fMsLS0RDocpFovyMY1F5S6Xi5aWFux2u4xTNmuW92GxWCz4/X68Xi9f/OIXeemll+TOtWImgLKbYicR519raytvvPEGvb29tLW1ybBYf3//zh7gJrDjoiuuaG63m3q9Tm9vL4VCgampKSKRCEajkfn5+Tse17idusViUeGEe6Cx6cHpdO7w0SgUv2Lt2Eun08ljjz3GE088QVtbG+3t7bIFeq+z46ILywYXA4mFkB47dgyj0Ugmk+HEiROr9vESgXWLxcLJkydVMb9CsYcJBAJ8+ctf5rOf/ewqT/f48eO0t7fjcrmwWq1N03mnrY2VruFTb9ws1h6DruuUy2W5Rcl6W0mLD0dc/XZwWfwwL7wt9t3jPKh9lW03ZlfYVjRHrFciJvIzjXvQ7ZEQ2F0PcleI7h5Hie7WsiuEoUlRtt067mrbve+rKxQKxR5Cia5CoVBsI0p0FQqFYhvZKKarUCgUik1EeboKhUKxjSjRVSgUim1Eia5CoVBsI0p0FQqFYhtRoqtQKBTbiBJdhUKh2Eb+P524uhiyng1pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    sub_plot = fig.add_subplot(1,4,i+1)\n",
    "    sub_plot.axis('Off')\n",
    "    plt.imshow(mb_example[0][i,0] * std + mean, cmap='Greys', interpolation=None)\n",
    "    sub_plot.set_title(mb_example[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to create a model as a subclass of nn.Module. That way, we can use all the features this class provides.\n",
    "\n",
    "We override the init function (but still call the init function of nn.Module) to define our custom layers (here two linear layers) and we have to define the forward function, which explains how to compute the output.\n",
    "\n",
    "The first line of the forward function is to flatten our input, since we saw it has four dimensions: minibatch by channel by height by width. We only keep the minibatch size as our first dimension (x.size(0)) and the -1 is to tell pytorch to determine the right number for the second dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_in, n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_out)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.log_softmax(self.linear2(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can instanciate the class with our input size (28 * 28), an hidden size of 100 layers and 10 outputs (as many as digits).\n",
    "\n",
    "The optimizer will automatically do the Stochastic Gradient Descent for us (or any of its variant if we want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10)\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to write our training loop. To compute the gradient automatically, pytorch requires us to put the torch tensors with our inputs and labels into Variable objects, that way it'll remember the transformation these go through until we arrive at our loss function. We then call loss.backward() to compute all the gradients (which will then be in the grad field of any variable).\n",
    "\n",
    "The optimizer takes care of the step of our gradient descent in the optimizer.step() function. Since the gradients are accumulated, we have to tell pytorch when to reinitialize them (which the purpose of the optimizer.zero_grad() command at the beginning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nb_epoch):\n",
    "    for epoch in range(nb_epoch):\n",
    "        running_loss = 0.\n",
    "        corrects = 0\n",
    "        print(f'Epoch {epoch+1}:')\n",
    "        for data in trn_loader:\n",
    "            #separate the inputs from the labels\n",
    "            inputs,labels = data\n",
    "            #wrap those into variables to keep track of how they are created and be able to compute their gradient.\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            #Put the gradients back to zero\n",
    "            optimizer.zero_grad()\n",
    "            #Compute the outputs given by our model at this stage.\n",
    "            outputs = net(inputs)\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            #Compute the loss\n",
    "            loss = F.nll_loss(outputs, labels)\n",
    "            running_loss += loss.data * inputs.size(0)\n",
    "            corrects += torch.sum(labels.data == preds)\n",
    "            #Backpropagate the computation of the gradients\n",
    "            loss.backward()\n",
    "            #Do the step of the SGD\n",
    "            optimizer.step()\n",
    "        print(f'Loss: {running_loss/len(trn_set)}  Accuracy: {100.*corrects/len(trn_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.5853068232536316  Accuracy: 84.9800033569336\n",
      "Epoch 2:\n",
      "Loss: 0.30118703842163086  Accuracy: 91.3566665649414\n",
      "Epoch 3:\n",
      "Loss: 0.25516441464424133  Accuracy: 92.6816635131836\n",
      "Epoch 4:\n",
      "Loss: 0.2240198254585266  Accuracy: 93.63666534423828\n",
      "Epoch 5:\n",
      "Loss: 0.19984345138072968  Accuracy: 94.33833312988281\n",
      "Epoch 6:\n",
      "Loss: 0.18068507313728333  Accuracy: 94.90666961669922\n",
      "Epoch 7:\n",
      "Loss: 0.164964959025383  Accuracy: 95.34666442871094\n",
      "Epoch 8:\n",
      "Loss: 0.1519738882780075  Accuracy: 95.69000244140625\n",
      "Epoch 9:\n",
      "Loss: 0.14120538532733917  Accuracy: 96.01166534423828\n",
      "Epoch 10:\n",
      "Loss: 0.13153965771198273  Accuracy: 96.30000305175781\n"
     ]
    }
   ],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.3% accuracy is good, but that's on the training set and we may be overfitting. Let's try on the test set now to see if we're doing well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    running_loss = 0.\n",
    "    corrects = 0\n",
    "    for data in tst_loader:\n",
    "        #separate the inputs from the labels\n",
    "        inputs,labels = data\n",
    "        #wrap those into variables to keep track of how they are created and be able to compute their gradient.\n",
    "        #Even if we don't require the gradient here, a nn.Module expects a variable.\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #Compute the outputs given by our model at this stage.\n",
    "        outputs = net(inputs)\n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        running_loss += loss.data * inputs.size(0)\n",
    "        corrects += torch.sum(labels.data == preds)\n",
    "    print(f'Loss: {running_loss/len(tst_set)}  Accuracy: {100.*corrects/len(tst_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13313183188438416  Accuracy: 96.0199966430664\n"
     ]
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we weren't overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of how this code has been built are all explained in this [blog article](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(trn_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in trn_loader:\n",
    "        batch_num += 1\n",
    "        #As before, get the loss for this mini-batch of inputs/outputs\n",
    "        inputs,labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) *loss.data\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        #Do the SGD step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "    return log_lrs, losses\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our neural net as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10)\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-1)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot the losses versus the logs of the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs,losses = find_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15520327688>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests the best learning rate is $10^{-1}$ so we can use test this one after defining a new network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.268404483795166  Accuracy: 92.14167022705078\n"
     ]
    }
   ],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10)\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-1)\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already at 92.21% accuracy when the learning rate used before gave us 84.86% in one epoch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Methods\n",
    "## Momentum\n",
    "---\n",
    "![title](img/speedup1.png)\n",
    "The traditional method of updating the neural network parameter W is to add the original W to a negative learning rate and multiply it by the correction value (dx). This method may make the learning process extremely tortuous, and it looks like a drunk man walks a lot of detours when he comes home.\n",
    "![title](img/speedup2.png)\n",
    "So we put this person from the flat ground onto a slope, as long as he walks a little bit downhill, because of the downward inertia, he unconsciously walks down, and the detours are reduced. It is the Momentum.\n",
    "\n",
    "---\n",
    "--CLASS torch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False)<br>\n",
    "### Parameters<br>\n",
    "- params (iterable)  iterable of parameters to optimize or dicts defining parameter groups\n",
    "\n",
    "- lr (float)  learning rate\n",
    "\n",
    "- momentum (float, optional)  momentum factor (default: 0)\n",
    "\n",
    "- weight_decay (float, optional)  weight decay (L2 penalty) (default: 0)\n",
    "\n",
    "- dampening (float, optional)  dampening for momentum (default: 0)\n",
    "\n",
    "- nesterov (bool, optional)  enables Nesterov momentum (default: False)\n",
    "\n",
    "## AdaGrad \n",
    "---\n",
    "![title](img/speedup3.png)\n",
    "\n",
    "---\n",
    "CLASS torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)<br>\n",
    "### Parameters<br>\n",
    "- params (iterable)  iterable of parameters to optimize or dicts defining parameter groups\n",
    "\n",
    "- lr (float, optional)  learning rate (default: 1e-2)\n",
    "\n",
    "- lr_decay (float, optional)  learning rate decay (default: 0)\n",
    "\n",
    "- weight_decay (float, optional)  weight decay (L2 penalty) (default: 0)\n",
    "\n",
    "- eps (float, optional)  term added to the denominator to improve numerical stability (default: 1e-10)\n",
    "\n",
    "## RMSprop\n",
    "---\n",
    "![title](img/speedup4.png)\n",
    "\n",
    "---\n",
    "CLASS torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "### Parameters<br>\n",
    "- params (iterable)  iterable of parameters to optimize or dicts defining parameter groups\n",
    "\n",
    "- lr (float, optional)  learning rate (default: 1e-2)\n",
    "\n",
    "- momentum (float, optional)  momentum factor (default: 0)\n",
    "\n",
    "- alpha (float, optional)  smoothing constant (default: 0.99)\n",
    "\n",
    "- eps (float, optional)  term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "\n",
    "- centered (bool, optional)  if True, compute the centered RMSProp, the gradient is normalized by an estimation of its variance\n",
    "\n",
    "- weight_decay (float, optional)  weight decay (L2 penalty) (default: 0)\n",
    "\n",
    "## Adam\n",
    "---\n",
    "![title](img/speedup5.png)\n",
    "\n",
    "---\n",
    "CLASS torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)<br>\n",
    "### Parameters<br>\n",
    "- params (iterable)  iterable of parameters to optimize or dicts defining parameter groups\n",
    "\n",
    "- lr (float, optional)  learning rate (default: 1e-3)\n",
    "\n",
    "- betas (Tuple[float, float], optional)  coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "\n",
    "- eps (float, optional)  term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "\n",
    "- weight_decay (float, optional)  weight decay (L2 penalty) (default: 0)\n",
    "\n",
    "- amsgrad (boolean, optional)  whether to use the AMSGrad variant of this algorithm from the paper On the Convergence of Adam and Beyond (default: False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Work\n",
    "## Question 1\n",
    "Using the following three optimizersMomentum, RMSProp, Adam to train the data in MNIST, find the appropriate learning rate and the accuracy of recognizing handwritten digits can reach more than 95% within ten epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_SGD = SimpleNeuralNet(28*28,100,10)\n",
    "net_Momentum = SimpleNeuralNet(28*28,100,10)\n",
    "net_RMSProp = SimpleNeuralNet(28*28,100,10)\n",
    "net_Adam = SimpleNeuralNet(28*28,100,10)\n",
    " \n",
    "nets = [net_SGD, net_Momentum, net_RMSProp, net_Adam]\n",
    " \n",
    "opt_SGD = torch.optim.SGD(net_SGD.parameters(), lr=1e-1)\n",
    "opt_Momentum = torch.optim.SGD(net_Momentum.parameters(), lr=1e-1, momentum=0.9)# You can change the learning rate or any other parameters \n",
    "opt_RMSProp = torch.optim.RMSprop(net_RMSProp.parameters(), lr=1e-1, alpha=0.9)# You can change the learning rate or any other parameters\n",
    "opt_Adam = torch.optim.Adam(net_Adam.parameters(), lr=1e-1, betas=(0.9, 0.99))# You can change the learning rate or any other parameters\n",
    "#loss_his = [[], [], [], []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SGD(nb_epoch):\n",
    "    for epoch in range(nb_epoch):\n",
    "        running_loss = 0.\n",
    "        corrects = 0\n",
    "        print(f'Epoch {epoch+1}:')\n",
    "        for data in trn_loader:\n",
    "            #separate the inputs from the labels\n",
    "            inputs,labels = data\n",
    "            #wrap those into variables to keep track of how they are created and be able to compute their gradient.\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            #Put the gradients back to zero\n",
    "            opt_SGD.zero_grad()\n",
    "            #Compute the outputs given by our model at this stage.\n",
    "            outputs = net_SGD(inputs)\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            #Compute the loss\n",
    "            loss = F.nll_loss(outputs, labels)\n",
    "            running_loss += loss.data * inputs.size(0)\n",
    "            corrects += torch.sum(labels.data == preds)\n",
    "            #Backpropagate the computation of the gradients\n",
    "            loss.backward()\n",
    "            #Do the step of the SGD\n",
    "            opt_SGD.step()\n",
    "        print(f'Loss: {running_loss/len(trn_set)}  Accuracy: {100.*corrects/len(trn_set)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.26417237520217896  Accuracy: 92.22833251953125\n",
      "Epoch 2:\n",
      "Loss: 0.11616211384534836  Accuracy: 96.53500366210938\n",
      "Epoch 3:\n",
      "Loss: 0.08202864229679108  Accuracy: 97.55999755859375\n",
      "Epoch 4:\n",
      "Loss: 0.06427153199911118  Accuracy: 98.0433349609375\n",
      "Epoch 5:\n",
      "Loss: 0.051903363317251205  Accuracy: 98.47833251953125\n",
      "Epoch 6:\n",
      "Loss: 0.04215460270643234  Accuracy: 98.76166534423828\n",
      "Epoch 7:\n",
      "Loss: 0.03457197919487953  Accuracy: 98.96833038330078\n",
      "Epoch 8:\n",
      "Loss: 0.028702011331915855  Accuracy: 99.16166687011719\n",
      "Epoch 9:\n",
      "Loss: 0.02329939417541027  Accuracy: 99.3566665649414\n",
      "Epoch 10:\n",
      "Loss: 0.019391683861613274  Accuracy: 99.49333190917969\n"
     ]
    }
   ],
   "source": [
    "train_SGD(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your answer below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Use the neural network defined below to train the CIFRA10 data set, classify the images in the data set and print out the classification accuracy of the test set.\n",
    "![title](img/di-01.png)\n",
    "\n",
    "Data and network have been prepared for you, your next task will be:\n",
    "- Choose the loss function and optimizer\n",
    "- Use the learning rate finder method to find the appropriate learning rate for the optimizer.\n",
    "- Training a neural network\n",
    "- Test training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data using torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))  \n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',train=True,download=True,transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    trainset,batch_size=4,shuffle=True,num_workers=0\n",
    ")\n",
    "\n",
    "testSet = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",train=False,download=True,transform=transform\n",
    ")\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(testSet,batch_size=4,shuffle=False,num_workers=0)\n",
    "\n",
    "classes =  ('airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_class",
   "language": "python",
   "name": "pytorch_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
